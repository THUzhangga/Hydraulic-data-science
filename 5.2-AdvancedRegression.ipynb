{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以叫Adavanced只是不想和前面的Regression重名\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入2001年至2010年的输入变量，距平并作标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "origin = np.load('total_used.npy')[:3287]\n",
    "\n",
    "loss = np.isnan(origin)\n",
    "\n",
    "origin[loss] = 0\n",
    "\n",
    "year_start = [0]\n",
    "\n",
    "for year in range(2002, 2010):\n",
    "\n",
    "    if (year - 1) % 4 == 0:\n",
    "\n",
    "        year_start += [year_start[-1] + 366]\n",
    "\n",
    "    else:\n",
    "\n",
    "        year_start += [year_start[-1] + 365]\n",
    "\n",
    "year_start = np.array(year_start)\n",
    "\n",
    "year_leap = [1460, 2921]\n",
    "\n",
    "day_average = np.zeros((366, 4763))\n",
    "\n",
    "for i in range(365):\n",
    "\n",
    "    day_average[i] = np.sum(origin[year_start + i], axis = 0) / np.sum(1 - loss[year_start + i], axis = 0)  # 求平均时不考虑缺失值\n",
    "\n",
    "    origin[year_start + i] -= day_average[i]  # 距平\n",
    "\n",
    "day_average[365] = np.sum(origin[year_leap], axis = 0) / np.sum(1 - loss[year_leap], axis = 0)  # 对于闰年中一年的第366天求平均\n",
    "\n",
    "origin[year_leap] -= day_average[365]  # 距平\n",
    "\n",
    "origin[loss] = 0  # 对于缺失值认为等于历史平均值，历史平均值的距平为0\n",
    "\n",
    "origin_std = np.std(origin, axis = 0) / ((np.sum(1 - loss, axis = 0) / 3287) ** 0.5)  # 距平相当于已经做了减均值处理，\n",
    "                                                                                      # 此处只需要除以方差即可\n",
    "\n",
    "origin /= origin_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将输入变量降至1000维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1000)\n",
    "\n",
    "pca.fit(origin)\n",
    "\n",
    "X = pca.fit_transform(origin)\n",
    "\n",
    "X = X[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入输出变量，距平，并将其相对输入变量后移一位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('y.npy')[:3287, 0]\n",
    "\n",
    "loss_y = np.isnan(y)\n",
    "\n",
    "y[loss_y] = 0\n",
    "\n",
    "y_day_average = np.zeros(366)\n",
    "\n",
    "for i in range(365):\n",
    "\n",
    "    y_day_average[i] = np.sum(y[year_start + i]) / np.sum(1 - loss_y[year_start + i])\n",
    "\n",
    "    y[year_start + i] -= y_day_average[i]\n",
    "\n",
    "y_day_average[365] = np.sum(y[year_leap]) / np.sum(1 - loss_y[year_leap])\n",
    "\n",
    "y[year_leap] -= y_day_average[365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[1:]\n",
    "\n",
    "loss_y = loss_y[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只拟合输出变量中观测值不缺失的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_y = loss_y == 0\n",
    "\n",
    "new_y = y[use_y]\n",
    "\n",
    "new_X = X[use_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用5折交叉验证发验证（因为5折要比10折省一半的时间……）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06 0.0001 3.7762624396219513\n",
      "1e-06 0.001 3.77624302933814\n",
      "1e-06 0.01 3.776365271062583\n",
      "1e-06 0.1 3.7767908913985075\n",
      "1e-06 1 3.7844151617155255\n",
      "1e-06 10 4.074643100257235\n",
      "1e-05 0.0001 2.9021552059444287\n",
      "1e-05 0.001 2.9021721098516577\n",
      "1e-05 0.01 2.902243458340473\n",
      "1e-05 0.1 2.9018608006836013\n",
      "1e-05 1 2.9301059007682118\n",
      "1e-05 10 3.7946043069161006\n",
      "0.0001 0.0001 2.4413764363991306\n",
      "0.0001 0.001 2.4413380040254546\n",
      "0.0001 0.01 2.440972829656327\n",
      "0.0001 0.1 2.4391477116587845\n",
      "0.0001 1 2.4409796299006805\n",
      "0.0001 10 3.2852675050901703\n",
      "0.001 0.0001 2.3644194409334114\n",
      "0.001 0.001 2.3643485657191423\n",
      "0.001 0.01 2.363618572725393\n",
      "0.001 0.1 2.356978295625651\n",
      "0.001 1 2.302852903404971\n",
      "0.001 10 3.003806169591558\n",
      "0.01 0.0001 2.6510182947028733\n",
      "0.01 0.001 2.6509491004085666\n",
      "0.01 0.01 2.6502939488836637\n",
      "0.01 0.1 2.6406369922885995\n",
      "0.01 1 2.5417877634544817\n",
      "0.01 10 2.966498802805132\n",
      "0.1 0.0001 2.874843771622226\n",
      "0.1 0.001 2.8745990834029507\n",
      "0.1 0.01 2.8727003923920797\n",
      "0.1 0.1 2.8569866334155547\n",
      "0.1 1 2.7226547617427306\n",
      "0.1 10 2.966498802805132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import sklearn.model_selection as sk_model_selection\n",
    "\n",
    "for i in (0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1):\n",
    "    for j in (0.0001, 0.001, 0.01, 0.1, 1, 10):\n",
    "        clf = SVR(kernel='linear', C=i, epsilon=j)\n",
    "        print(i, j, abs(np.average(sk_model_selection.cross_val_score(clf, new_X, new_y, scoring='neg_mean_absolute_error', cv = 5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用线性回归和SVR做对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7311729783382788\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.LinearRegression()\n",
    "\n",
    "print(abs(np.average(sk_model_selection.cross_val_score(clf, new_X, new_y, scoring='neg_mean_absolute_error', cv = 5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入2001年至2009年的输入变量，距平并作标准化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "origin = np.load('total_used.npy')[:3287]\n",
    "\n",
    "loss = np.isnan(origin)\n",
    "\n",
    "origin[loss] = 0\n",
    "\n",
    "year_start = [0]\n",
    "\n",
    "for year in range(2002, 2010):\n",
    "\n",
    "    if (year - 1) % 4 == 0:\n",
    "\n",
    "        year_start += [year_start[-1] + 366]\n",
    "\n",
    "    else:\n",
    "\n",
    "        year_start += [year_start[-1] + 365]\n",
    "\n",
    "year_start = np.array(year_start)\n",
    "\n",
    "year_leap = [1460, 2921]\n",
    "\n",
    "day_average = np.zeros((366, 4763))\n",
    "\n",
    "for i in range(365):\n",
    "\n",
    "    day_average[i] = np.sum(origin[year_start + i], axis = 0) / np.sum(1 - loss[year_start + i], axis = 0)  # 求平均时不考虑缺失值\n",
    "\n",
    "    origin[year_start + i] -= day_average[i]  # 距平\n",
    "\n",
    "day_average[365] = np.sum(origin[year_leap], axis = 0) / np.sum(1 - loss[year_leap], axis = 0)  # 对于闰年中一年的第366天求平均\n",
    "\n",
    "origin[year_leap] -= day_average[365]  # 距平\n",
    "\n",
    "origin[loss] = 0  # 对于缺失值认为等于历史平均值，历史平均值的距平为0\n",
    "\n",
    "origin_std = np.std(origin, axis = 0) / ((np.sum(1 - loss, axis = 0) / 3287) ** 0.5)  # 距平相当于已经做了减均值处理，\n",
    "                                                                                      # 此处只需要除以方差即可\n",
    "\n",
    "origin /= origin_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将输入变量降至1000维"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=1000)\n",
    "\n",
    "pca.fit(origin)\n",
    "\n",
    "X = pca.fit_transform(origin)\n",
    "\n",
    "X = X[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入输出变量，距平，并将其相对输入变量后移一位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.load('y.npy')[:3287, 0]\n",
    "\n",
    "loss_y = np.isnan(y)\n",
    "\n",
    "y[loss_y] = 0\n",
    "\n",
    "y_day_average = np.zeros(366)\n",
    "\n",
    "for i in range(365):\n",
    "\n",
    "    y_day_average[i] = np.sum(y[year_start + i]) / np.sum(1 - loss_y[year_start + i])\n",
    "\n",
    "    y[year_start + i] -= y_day_average[i]\n",
    "\n",
    "y_day_average[365] = np.sum(y[year_leap]) / np.sum(1 - loss_y[year_leap])\n",
    "\n",
    "y[year_leap] -= y_day_average[365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[1:]\n",
    "\n",
    "loss_y = loss_y[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只拟合输出变量中观测值不缺失的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_y = loss_y == 0\n",
    "\n",
    "new_y = y[use_y]\n",
    "\n",
    "new_X = X[use_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=0.001, cache_size=200, coef0=0.0, degree=3, epsilon=1,\n",
       "  gamma='auto_deprecated', kernel='linear', max_iter=-1, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "clf = SVR(kernel='linear', C=0.001, epsilon=1)\n",
    "\n",
    "clf.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "reg.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入2009年12月31日（含）至2010年12月30日的输入变量（含），使用训练集的历史平均值和训练集的pca基底对其进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_valid = np.load('total_used.npy')[3286:3651]\n",
    "\n",
    "loss_valid = np.isnan(origin_valid)\n",
    "\n",
    "for i in range(364):\n",
    "\n",
    "    origin_valid[i + 1] -= day_average[i]  # origin_valid中第2天才是一年中的第1天\n",
    "\n",
    "origin_valid[0] -= day_average[-2]\n",
    "\n",
    "origin_valid[loss_valid] = 0  # 将缺失值设为历史平均值\n",
    "\n",
    "origin_valid /= origin_std\n",
    "\n",
    "X_valid = origin_valid @ pca.components_.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测并加回历史平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = clf.predict(X_valid) + y_day_average[:-1]  # 2010年不是闰年"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入2010年1月1日至2010年12月31日的输出变量，并做验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8303017062124693"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.load('y.npy')[3287:3652, 0]\n",
    "\n",
    "mae = np.average(abs(y_valid - y_true))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.393351753572736"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.average(abs(y_valid - y_day_average[:-1]))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_linearreg = reg.predict(X_valid) + y_day_average[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3520955584137"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae = np.average(abs(y_valid - y_linearreg))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('y.txt', np.vstack((y_true, y_valid, y_day_average[:-1], y_linearreg)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 0.0001 3.927452941164313\n",
      "0.01 0.001 3.927427268323316\n",
      "0.01 0.01 3.927349540945368\n",
      "0.01 0.1 3.928490327463261\n",
      "0.01 1 3.9308950558193487\n",
      "0.01 10 4.109513596855781\n",
      "0.01 100 4.163456972059292\n",
      "0.1 0.0001 3.212793751753722\n",
      "0.1 0.001 3.212775097777663\n",
      "0.1 0.01 3.2126803331749563\n",
      "0.1 0.1 3.2140051394332545\n",
      "0.1 1 3.236185187659436\n",
      "0.1 10 3.953866881460132\n",
      "0.1 100 4.163456972059292\n",
      "1 0.0001 2.634410043439544\n",
      "1 0.001 2.634410598022209\n",
      "1 0.01 2.634460322730633\n",
      "1 0.1 2.6341091336239004\n",
      "1 1 2.638778782882066\n",
      "1 10 3.5379579064799835\n",
      "1 100 4.163456972059292\n",
      "10 0.0001 2.470599627249307\n",
      "10 0.001 2.4705877440944457\n",
      "10 0.01 2.4704934205193463\n",
      "10 0.1 2.469470649384615\n",
      "10 1 2.471937338769594\n",
      "10 10 3.2858677866909964\n",
      "10 100 4.163456972059292\n",
      "100 0.0001 2.500093156993598\n",
      "100 0.001 2.500063217240568\n",
      "100 0.01 2.4997946994299705\n",
      "100 0.1 2.4974561652699885\n",
      "100 1 2.4890571206253638\n",
      "100 10 3.2858677866909964\n",
      "100 100 4.163456972059292\n",
      "1000 0.0001 2.500093156993598\n",
      "1000 0.001 2.500063217240568\n",
      "1000 0.01 2.4997946994299705\n",
      "1000 0.1 2.4974561652699885\n",
      "1000 1 2.4890571206253638\n",
      "1000 10 3.2858677866909964\n",
      "1000 100 4.163456972059292\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "import sklearn.model_selection as sk_model_selection\n",
    "\n",
    "for i in (0.01, 0.1, 1, 10, 100, 1000):\n",
    "    for j in (0.0001, 0.001, 0.01, 0.1, 1, 10, 100):\n",
    "        clf = SVR(gamma='scale', C=i, epsilon=j)\n",
    "        print(i, j, abs(np.average(sk_model_selection.cross_val_score(clf, new_X, new_y, scoring='neg_mean_absolute_error', cv = 5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.01, gamma='scale',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "clf = SVR(gamma='scale', C=10, epsilon=0.01)\n",
    "\n",
    "clf.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = clf.predict(X_valid) + y_day_average[:-1]\n",
    "np.savetxt('RBFSVM.txt', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.096349622588674"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.load('y.npy')[3287:3652, 0]\n",
    "\n",
    "mae = np.average(abs(y_valid - y_true))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3.4894812269091657\n",
      "3 3.391846277124871\n",
      "4 3.4021654441879305\n",
      "5 3.4473692377516643\n",
      "6 3.6057647638867047\n",
      "7 3.775876609274878\n",
      "8 3.9164711889007413\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import sklearn.model_selection as sk_model_selection\n",
    "\n",
    "for i in range(2, 9):\n",
    "    clf = DecisionTreeRegressor(max_depth=i)\n",
    "    print(i, abs(np.average(sk_model_selection.cross_val_score(clf, new_X, new_y, scoring='neg_mean_absolute_error', cv = 5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=3, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "clf = DecisionTreeRegressor(max_depth=3)\n",
    "\n",
    "clf.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = clf.predict(X_valid) + y_day_average[:-1]\n",
    "\n",
    "np.savetxt('DT.txt', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6148419242727843"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.load('y.npy')[3287:3652, 0]\n",
    "\n",
    "mae = np.average(abs(y_valid - y_true))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3.4319333325581356\n",
      "3 3.259596689628288\n",
      "4 3.157117372954301\n",
      "5 3.1239349683423265\n",
      "6 3.1111357027615574\n",
      "7 3.091303560417791\n",
      "8 3.0860126801880483\n",
      "9 3.0960295797533877\n",
      "10 3.091931452303018\n",
      "11 3.0965109319634587\n",
      "12 3.0988412054890375\n",
      "13 3.092423547554343\n",
      "14 3.1082729912058396\n",
      "15 3.075739671587096\n",
      "16 3.1034251508104287\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import sklearn.model_selection as sk_model_selection\n",
    "\n",
    "for i in range(2, 17):\n",
    "    clf = RandomForestRegressor(max_depth=i, n_estimators=100)\n",
    "    print(i, abs(np.average(sk_model_selection.cross_val_score(clf, new_X, new_y, scoring='neg_mean_absolute_error', cv = 5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "clf = RandomForestRegressor(max_depth=8, n_estimators=100)\n",
    "\n",
    "clf.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = clf.predict(X_valid) + y_day_average[:-1]\n",
    "\n",
    "np.savetxt('RF.txt', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.086623246458305"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.load('y.npy')[3287:3652, 0]\n",
    "\n",
    "mae = np.average(abs(y_valid - y_true))\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1000, 3)\n",
    "        self.fc2 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(new_X).float()\n",
    "X_test = torch.from_numpy(X_valid).float()\n",
    "y_train = torch.from_numpy(np.array([new_y]).T).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 27.78514289855957\n",
      "501 26.5269775390625\n",
      "1001 25.36873435974121\n",
      "1501 24.271699905395508\n",
      "2001 23.222030639648438\n",
      "2501 22.221590042114258\n",
      "3001 21.2681827545166\n",
      "3501 20.3751163482666\n",
      "4001 19.526918411254883\n",
      "4501 18.72639274597168\n",
      "5001 17.971839904785156\n",
      "5501 17.263669967651367\n",
      "6001 16.597654342651367\n",
      "6501 15.964357376098633\n",
      "7001 15.366880416870117\n",
      "7501 14.801788330078125\n",
      "8001 14.26591682434082\n",
      "8501 13.756755828857422\n",
      "9001 13.268279075622559\n",
      "9501 12.799700736999512\n",
      "10001 12.351975440979004\n",
      "10501 11.921003341674805\n",
      "11001 11.50158977508545\n",
      "11501 11.098526954650879\n",
      "12001 10.706625938415527\n",
      "12501 10.328885078430176\n",
      "13001 9.964238166809082\n",
      "13501 9.60960865020752\n",
      "14001 9.26612377166748\n",
      "14501 8.9329195022583\n",
      "15001 8.609207153320312\n",
      "15501 8.29646110534668\n",
      "16001 7.99355936050415\n",
      "16501 7.7023115158081055\n",
      "17001 7.421689987182617\n",
      "17501 7.152163028717041\n",
      "18001 6.895515441894531\n",
      "18501 6.64851713180542\n",
      "19001 6.408320903778076\n",
      "19501 6.180277347564697\n",
      "20001 5.961472034454346\n",
      "20501 5.7553229331970215\n",
      "21001 5.557785511016846\n",
      "21501 5.3654704093933105\n",
      "22001 5.183453559875488\n",
      "22501 5.009978771209717\n",
      "23001 4.8394646644592285\n",
      "23501 4.680845260620117\n",
      "24001 4.533734321594238\n",
      "24501 4.39124870300293\n",
      "25001 4.244953155517578\n",
      "25501 4.109666347503662\n",
      "26001 3.984367609024048\n",
      "26501 3.867619276046753\n",
      "27001 3.7589516639709473\n",
      "27501 3.6522674560546875\n",
      "28001 3.5545008182525635\n",
      "28501 3.46112060546875\n",
      "29001 3.370253086090088\n",
      "29501 3.285198450088501\n",
      "30001 3.206162691116333\n",
      "30501 3.1314635276794434\n",
      "31001 3.0637900829315186\n",
      "31501 3.0024819374084473\n",
      "32001 2.942373752593994\n",
      "32501 2.8878965377807617\n",
      "33001 2.8331687450408936\n",
      "33501 2.7840285301208496\n",
      "34001 2.738295793533325\n",
      "34501 2.6843669414520264\n",
      "35001 2.636378049850464\n",
      "35501 2.592003107070923\n",
      "36001 2.551305055618286\n",
      "36501 2.5122780799865723\n",
      "37001 2.471747875213623\n",
      "37501 2.434581995010376\n",
      "38001 2.3964946269989014\n",
      "38501 2.3597967624664307\n",
      "39001 2.325225830078125\n",
      "39501 2.292288064956665\n",
      "40001 2.2554571628570557\n",
      "40501 2.2205541133880615\n",
      "41001 2.189753293991089\n",
      "41501 2.1605448722839355\n",
      "42001 2.131326198577881\n",
      "42501 2.1022300720214844\n",
      "43001 2.074512243270874\n",
      "43501 2.048762321472168\n",
      "44001 2.025270462036133\n",
      "44501 2.000492811203003\n",
      "45001 1.9666639566421509\n",
      "45501 1.9402743577957153\n",
      "46001 1.914486050605774\n",
      "46501 1.8913480043411255\n",
      "47001 1.870540738105774\n",
      "47501 1.8509070873260498\n",
      "48001 1.8317078351974487\n",
      "48501 1.813106656074524\n",
      "49001 1.7944540977478027\n",
      "49501 1.775594711303711\n",
      "50001 1.7569247484207153\n",
      "50501 1.7384916543960571\n",
      "51001 1.7206734418869019\n",
      "51501 1.7032825946807861\n",
      "52001 1.6821043491363525\n",
      "52501 1.6627975702285767\n",
      "53001 1.6464227437973022\n",
      "53501 1.6309219598770142\n",
      "54001 1.6158347129821777\n",
      "54501 1.6013977527618408\n",
      "55001 1.5864804983139038\n",
      "55501 1.5720380544662476\n",
      "56001 1.5577327013015747\n",
      "56501 1.5442931652069092\n",
      "57001 1.5267678499221802\n",
      "57501 1.5085572004318237\n",
      "58001 1.4948009252548218\n",
      "58501 1.482365608215332\n",
      "59001 1.4706162214279175\n",
      "59501 1.4594619274139404\n",
      "60001 1.447129487991333\n",
      "60501 1.4358248710632324\n",
      "61001 1.4255315065383911\n",
      "61501 1.415200114250183\n",
      "62001 1.4026315212249756\n",
      "62501 1.3908179998397827\n",
      "63001 1.380082130432129\n",
      "63501 1.3704280853271484\n",
      "64001 1.360331654548645\n",
      "64501 1.3511102199554443\n",
      "65001 1.3412668704986572\n",
      "65501 1.331515908241272\n",
      "66001 1.3226497173309326\n",
      "66501 1.3145778179168701\n",
      "67001 1.3065598011016846\n",
      "67501 1.2984001636505127\n",
      "68001 1.289089322090149\n",
      "68501 1.2778675556182861\n",
      "69001 1.2670894861221313\n",
      "69501 1.2579599618911743\n",
      "70001 1.2490743398666382\n",
      "70501 1.2400091886520386\n",
      "71001 1.231825351715088\n",
      "71501 1.2236320972442627\n",
      "72001 1.2149789333343506\n",
      "72501 1.2075037956237793\n",
      "73001 1.2001454830169678\n",
      "73501 1.1928348541259766\n",
      "74001 1.1857377290725708\n",
      "74501 1.1789641380310059\n",
      "75001 1.1724247932434082\n",
      "75501 1.16462242603302\n",
      "76001 1.1573635339736938\n",
      "76501 1.1502840518951416\n",
      "77001 1.1429296731948853\n",
      "77501 1.1353240013122559\n",
      "78001 1.1275219917297363\n",
      "78501 1.1202398538589478\n",
      "79001 1.1128042936325073\n",
      "79501 1.10403311252594\n",
      "80001 1.0969328880310059\n",
      "80501 1.0909978151321411\n",
      "81001 1.0848833322525024\n",
      "81501 1.0789941549301147\n",
      "82001 1.073589563369751\n",
      "82501 1.0682227611541748\n",
      "83001 1.0632447004318237\n",
      "83501 1.0576386451721191\n",
      "84001 1.0521583557128906\n",
      "84501 1.0472078323364258\n",
      "85001 1.0409682989120483\n",
      "85501 1.0349178314208984\n",
      "86001 1.0279605388641357\n",
      "86501 1.0212420225143433\n",
      "87001 1.0151139497756958\n",
      "87501 1.0098994970321655\n",
      "88001 1.0054455995559692\n",
      "88501 1.001097559928894\n",
      "89001 0.9970900416374207\n",
      "89501 0.9932938814163208\n",
      "90001 0.9890064597129822\n",
      "90501 0.9846131801605225\n",
      "91001 0.9809011816978455\n",
      "91501 0.977601170539856\n",
      "92001 0.9731693267822266\n",
      "92501 0.9691787958145142\n",
      "93001 0.9641218781471252\n",
      "93501 0.9580923318862915\n",
      "94001 0.9535732269287109\n",
      "94501 0.949619472026825\n",
      "95001 0.9464302659034729\n",
      "95501 0.9436033964157104\n",
      "96001 0.9381590485572815\n",
      "96501 0.9343015551567078\n",
      "97001 0.930381178855896\n",
      "97501 0.9263152480125427\n",
      "98001 0.9218242168426514\n",
      "98501 0.9178467392921448\n",
      "99001 0.9146324992179871\n",
      "99501 0.911083996295929\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 500 == 0:\n",
    "        print(epoch + 1, float(loss[0]))\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = net(X_test).detach().numpy().T[0] + y_day_average[:-1]\n",
    "\n",
    "np.savetxt('NN.txt', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7146772026689084"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = np.load('y.npy')[3287:3652, 0]\n",
    "\n",
    "mae = np.average(abs(y_valid - y_true))\n",
    "mae"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
