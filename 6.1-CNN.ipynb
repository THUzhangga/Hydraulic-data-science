{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler #only can be imported above pytorch0.2.0\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool0 = nn.AvgPool2d((2, 4), padding=1)\n",
    "        self.conv1 = nn.Conv2d(1, 5, 4)\n",
    "        self.pool1 = nn.AvgPool2d(3)\n",
    "        self.conv2 = nn.Conv2d(5, 5, 3)\n",
    "        self.pool2 = nn.MaxPool2d(3)\n",
    "        self.fc1 = nn.Linear(80, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool0(x)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 5*4*4)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4  # netCDF4非Python自带包，需要自行下载\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "f = netCDF4.Dataset('D:\\\\sst.mnmean.nc')  # ftp://ftp.cdc.noaa.gov/Datasets/noaa.ersst.v5/sst.mnmean.nc\n",
    "SST = f.variables['sst'][-1203:, :, :].data\n",
    "\n",
    "SST[SST < -2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mean = np.zeros((12, 89, 180))\n",
    "month_s = np.arange(0, 1188, 12)\n",
    "for i in range(12):\n",
    "    month_mean[i] = np.average(SST[month_s + i], axis = 0)\n",
    "    SST[month_s + i] -= month_mean[i]\n",
    "for i in range(12):\n",
    "    SST[1188 + i] -= month_mean[i]\n",
    "for i in range(3):\n",
    "    SST[1200 + i] -= month_mean[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST = SST.reshape((1200, 1, 89, 180))\n",
    "\n",
    "X_train = SST[:-16]\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_valid = SST[-16:-4]\n",
    "X_valid = torch.from_numpy(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ((134, 44), \\\n",
    "       (94, 44), \\\n",
    "       (57, 37), \\\n",
    "       (39, 44), \\\n",
    "       (21, 36), \\\n",
    "       (9, 16), \\\n",
    "       (172, 59), \\\n",
    "       (158, 28), \\\n",
    "       (65, 64), \\\n",
    "       (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0465993881225586 0.6835797429084778\n",
      "1 0.9747850298881531 0.6549382209777832\n",
      "2 0.8863504528999329 0.6098104119300842\n",
      "3 0.7840589284896851 0.5596358180046082\n",
      "4 0.6766080260276794 0.5468974709510803\n",
      "5 0.5807129144668579 0.7936881184577942\n",
      "6 0.5363522171974182 1.088138222694397\n",
      "7 0.5773686766624451 0.8834357261657715\n",
      "8 0.615320086479187 0.9258086085319519\n",
      "9 0.5854175686836243 0.7049086093902588\n",
      "......\n",
      "490 0.13504692912101746 0.2542419135570526\n",
      "491 0.13465538620948792 0.2536483705043793\n",
      "492 0.134561225771904 0.2488059401512146\n",
      "493 0.13465766608715057 0.25551173090934753\n",
      "494 0.13477489352226257 0.246018648147583\n",
      "495 0.13469943404197693 0.2529502809047699\n",
      "496 0.13452135026454926 0.24460838735103607\n",
      "497 0.13427981734275818 0.24881041049957275\n",
      "498 0.13404397666454315 0.2467304915189743\n",
      "499 0.1338791698217392 0.2460906058549881\n"
     ]
    }
   ],
   "source": [
    "for row in loc:\n",
    "    y_train = SST[1:-15, :, row[1], row[0]]\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    y_valid = SST[-15:-3, :, row[1], row[0]]\n",
    "    y_valid = torch.from_numpy(y_valid)\n",
    "\n",
    "    for epoch in range(500):  # loop over the dataset multiple times\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        outputs_valid = net(X_valid)\n",
    "        loss_valid = criterion(outputs_valid, y_valid)\n",
    "        print(epoch, loss.item(), loss_valid.item())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（92°W，0°）今年3月份海温（真实值为27.26599℃）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 26.5089]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = SST[-2].reshape((1, 1, 89, 180))\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "y_fore = net(X_test) + month_mean[2, row[1], row[0]]\n",
    "y_fore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "双通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler #only can be imported above pytorch0.2.0\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.pool0 = nn.AvgPool2d((2, 4), padding=1)\n",
    "        self.conv1 = nn.Conv2d(2, 5, 4)\n",
    "        self.pool1 = nn.AvgPool2d(3)\n",
    "        self.conv2 = nn.Conv2d(5, 5, 3)\n",
    "        self.pool2 = nn.AvgPool2d(3)\n",
    "        self.fc1 = nn.Linear(80, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool0(x)\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 5*4*4)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4  # netCDF4非Python自带包，需要自行下载\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "f = netCDF4.Dataset('D:\\\\sst.mnmean.nc')  # ftp://ftp.cdc.noaa.gov/Datasets/noaa.ersst.v5/sst.mnmean.nc\n",
    "SST = f.variables['sst'][-1203:, :, :].data\n",
    "\n",
    "SST[SST < -2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_mean = np.zeros((12, 89, 180))\n",
    "month_s = np.arange(0, 1188, 12)\n",
    "for i in range(12):\n",
    "    month_mean[i] = np.average(SST[month_s + i], axis = 0)\n",
    "    SST[month_s + i] -= month_mean[i]\n",
    "for i in range(12):\n",
    "    SST[1188 + i] -= month_mean[i]\n",
    "for i in range(3):\n",
    "    SST[1200 + i] -= month_mean[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST = SST.reshape((1203, 1, 89, 180))\n",
    "\n",
    "X_train = np.zeros((1186, 2, 89, 180), dtype=np.float32)\n",
    "X_train[:, 0] = SST[:-17, 0]\n",
    "X_train[:, 1] = SST[1:-16, 0]\n",
    "X_train = torch.from_numpy(X_train)\n",
    "\n",
    "X_valid = np.zeros((12, 2, 89, 180), dtype=np.float32)\n",
    "X_valid[:, 0] = SST[-17:-5, 0]\n",
    "X_valid[:, 1] = SST[-16:-4, 0]\n",
    "X_valid = torch.from_numpy(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = ((134, 44), \\\n",
    "       (94, 44), \\\n",
    "       (57, 37), \\\n",
    "       (39, 44), \\\n",
    "       (21, 36), \\\n",
    "       (9, 16), \\\n",
    "       (172, 59), \\\n",
    "       (158, 28), \\\n",
    "       (65, 64), \\\n",
    "       (0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0924222469329834 0.7783412933349609\n",
      "1 1.0704162120819092 0.7477688789367676\n",
      "2 1.0477246046066284 0.7139258980751038\n",
      "3 1.017866849899292 0.689863920211792\n",
      "4 0.9753577709197998 0.7009252905845642\n",
      "5 0.9219707250595093 0.7884209156036377\n",
      "6 0.8792669177055359 0.9841131567955017\n",
      "7 0.8626843690872192 1.0334067344665527\n",
      "8 0.8389838337898254 0.8623300194740295\n",
      "9 0.7954409718513489 0.656138002872467\n",
      "......\n",
      "490 0.14715714752674103 0.14399534463882446\n",
      "491 0.14776194095611572 0.14386199414730072\n",
      "492 0.15010632574558258 0.15215153992176056\n",
      "493 0.15140803158283234 0.14585167169570923\n",
      "494 0.15049022436141968 0.14933845400810242\n",
      "495 0.14814625680446625 0.14477448165416718\n",
      "496 0.1465679109096527 0.14365209639072418\n",
      "497 0.14680719375610352 0.1474066525697708\n",
      "498 0.14811305701732635 0.14321763813495636\n",
      "499 0.14914001524448395 0.14752419292926788\n"
     ]
    }
   ],
   "source": [
    "for row in loc:\n",
    "    y_train = SST[2:-15, :, row[1], row[0]]\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    y_valid = SST[-15:-3, :, row[1], row[0]]\n",
    "    y_valid = torch.from_numpy(y_valid)\n",
    "    \n",
    "    net = Net()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(500):  # loop over the dataset multiple times\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        outputs_valid = net(X_valid)\n",
    "        loss_valid = criterion(outputs_valid, y_valid)\n",
    "        print(epoch, loss.item(), loss_valid.item())\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight\n",
      "tensor([[[[ 0.1510, -0.1077, -0.0834,  0.0309],\n",
      "          [-0.0083, -0.0001, -0.1092,  0.1961],\n",
      "          [-0.1258, -0.0724,  0.0615,  0.2049],\n",
      "          [-0.2861, -0.2778, -0.0905,  0.0435]],\n",
      "\n",
      "         [[ 0.2954,  0.3766,  0.2090,  0.3081],\n",
      "          [ 0.2486,  0.3672,  0.3810,  0.5710],\n",
      "          [-0.2887,  0.1020,  0.2948,  0.5198],\n",
      "          [-0.3312,  0.2737,  0.4264,  0.2467]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4285,  0.3927,  0.4240,  0.3062],\n",
      "          [ 0.2997,  0.3778,  0.2909,  0.1247],\n",
      "          [ 0.1028, -0.0430, -0.0430, -0.0094],\n",
      "          [ 0.1991, -0.1548, -0.1521, -0.2047]],\n",
      "\n",
      "         [[-0.3585, -0.3561,  0.0138, -0.1086],\n",
      "          [ 0.0507, -0.1134, -0.1795,  0.0252],\n",
      "          [ 0.1738,  0.0330, -0.1451, -0.1173],\n",
      "          [ 0.1612, -0.1298, -0.3141, -0.5173]]],\n",
      "\n",
      "\n",
      "        [[[-0.1371, -0.0787, -0.1715, -0.0309],\n",
      "          [ 0.0039, -0.1633,  0.0560, -0.0061],\n",
      "          [-0.1149, -0.2434, -0.0266,  0.1660],\n",
      "          [-0.3392, -0.1659,  0.0258,  0.3732]],\n",
      "\n",
      "         [[ 0.1501,  0.3417,  0.4167,  0.4555],\n",
      "          [-0.0870,  0.1352,  0.2660,  0.2673],\n",
      "          [-0.3944, -0.1415,  0.3848,  0.5142],\n",
      "          [-0.4450,  0.0302,  0.4840,  0.4777]]],\n",
      "\n",
      "\n",
      "        [[[-0.1583, -0.1563, -0.3127, -0.2778],\n",
      "          [ 0.2006,  0.0502, -0.3626, -0.1617],\n",
      "          [ 0.1844,  0.2762, -0.0053, -0.0764],\n",
      "          [-0.1449,  0.0084,  0.2963,  0.0297]],\n",
      "\n",
      "         [[ 0.4629,  0.6646,  0.3475,  0.6647],\n",
      "          [ 0.8370,  0.7017,  0.1736, -0.0461],\n",
      "          [ 0.0439,  0.0211, -0.3282, -0.1299],\n",
      "          [-0.9520, -0.3390, -0.3739, -0.1620]]],\n",
      "\n",
      "\n",
      "        [[[-0.0559,  0.2675,  0.3751, -0.2588],\n",
      "          [-0.3625, -0.1360, -0.3303, -0.6004],\n",
      "          [-0.0493,  0.4136,  0.0235, -0.5815],\n",
      "          [-0.2132,  0.2809,  0.1576, -0.4575]],\n",
      "\n",
      "         [[-0.5167, -0.3597, -0.2198, -0.2539],\n",
      "          [-0.5517, -0.2284, -0.3297,  0.0388],\n",
      "          [ 0.0135,  0.1638, -0.1138, -0.3039],\n",
      "          [ 0.3454,  0.4423, -0.2709, -0.7258]]]])\n",
      "conv1.bias\n",
      "tensor([-0.2446,  0.4220,  0.2814,  0.7510,  0.5875])\n",
      "conv2.weight\n",
      "tensor([[[[-0.2499, -0.4626,  0.3272],\n",
      "          [ 0.1160, -0.3250, -0.0463],\n",
      "          [ 0.2020,  0.3089,  0.1159]],\n",
      "\n",
      "         [[ 0.1973, -0.1197, -0.0812],\n",
      "          [ 0.4484,  0.0348,  0.3189],\n",
      "          [-0.2392, -0.0594, -0.0506]],\n",
      "\n",
      "         [[-0.3009, -0.0844,  0.0984],\n",
      "          [-0.1969, -0.0252, -0.2745],\n",
      "          [-0.1823,  0.6401, -0.0894]],\n",
      "\n",
      "         [[ 0.6051,  0.3174, -0.2522],\n",
      "          [-0.2121, -0.7371,  0.6051],\n",
      "          [ 0.5788,  0.3637,  0.1411]],\n",
      "\n",
      "         [[-0.1888, -0.0917,  0.1650],\n",
      "          [ 0.7506,  0.0510,  0.1944],\n",
      "          [ 0.2760, -0.2248, -0.0407]]],\n",
      "\n",
      "\n",
      "        [[[-0.1816, -0.2668, -0.1354],\n",
      "          [-0.0841,  0.9680,  0.0282],\n",
      "          [-0.2288, -0.1297, -0.5382]],\n",
      "\n",
      "         [[ 0.2952, -0.4001,  0.0430],\n",
      "          [ 0.1763,  0.1325,  0.0887],\n",
      "          [ 0.0851,  0.2326, -0.3583]],\n",
      "\n",
      "         [[-0.5769, -0.3497, -0.4607],\n",
      "          [ 0.1989,  0.6201,  0.2780],\n",
      "          [ 0.0215, -0.0620,  0.0642]],\n",
      "\n",
      "         [[-0.2006, -0.3358, -0.0192],\n",
      "          [ 0.9779,  0.5627, -0.0155],\n",
      "          [-0.5387,  0.0809,  0.2561]],\n",
      "\n",
      "         [[-0.1303,  0.3592, -0.4686],\n",
      "          [ 0.1834,  0.2428,  0.3579],\n",
      "          [ 0.2068,  0.0642, -0.1764]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0211, -0.0927, -0.1489],\n",
      "          [ 0.0871,  0.0107,  0.2270],\n",
      "          [-0.5510,  0.0397,  0.0443]],\n",
      "\n",
      "         [[-0.3447, -0.2502, -0.1236],\n",
      "          [-0.0493, -0.0453,  0.1023],\n",
      "          [ 0.0759,  0.1012,  0.2009]],\n",
      "\n",
      "         [[-0.0059, -0.0185,  0.0804],\n",
      "          [ 0.1105,  0.0602,  0.3627],\n",
      "          [-0.4522, -0.0874,  0.4797]],\n",
      "\n",
      "         [[-0.1336,  0.0174, -0.0995],\n",
      "          [-0.0195, -0.1921, -0.0243],\n",
      "          [-0.1147,  0.0646,  0.1708]],\n",
      "\n",
      "         [[-0.1249, -0.2340,  0.3405],\n",
      "          [-0.3876, -0.0232,  0.1827],\n",
      "          [ 0.0662,  0.0554, -0.0251]]],\n",
      "\n",
      "\n",
      "        [[[-0.1229,  0.0901,  0.0245],\n",
      "          [ 0.0667,  0.1387,  0.2496],\n",
      "          [ 0.0899,  0.3017,  0.2095]],\n",
      "\n",
      "         [[-0.1149, -0.5030, -0.4707],\n",
      "          [ 0.0813, -0.2283, -0.4535],\n",
      "          [ 0.2469, -0.0536, -0.1991]],\n",
      "\n",
      "         [[-0.2040,  0.3841,  0.0018],\n",
      "          [-0.1532, -0.0096,  0.3012],\n",
      "          [ 0.1846, -0.0343, -0.0898]],\n",
      "\n",
      "         [[-0.2761,  0.1145, -0.0323],\n",
      "          [-0.1445,  0.5707, -0.0332],\n",
      "          [ 0.2017,  0.1138, -0.4934]],\n",
      "\n",
      "         [[-0.8600,  0.0364,  0.2116],\n",
      "          [-0.3295,  0.2762,  0.6649],\n",
      "          [ 0.2353, -0.3199, -1.0055]]],\n",
      "\n",
      "\n",
      "        [[[-0.5778, -0.3324,  0.3905],\n",
      "          [-0.3114, -0.0774,  0.1546],\n",
      "          [-0.1606, -0.2505, -0.0312]],\n",
      "\n",
      "         [[ 0.0879,  0.5694,  0.2327],\n",
      "          [-0.5148,  0.3821,  0.0157],\n",
      "          [-0.5978, -0.1693,  0.2803]],\n",
      "\n",
      "         [[-0.5098, -0.1960,  0.1132],\n",
      "          [-0.0743, -0.3413, -0.2445],\n",
      "          [ 0.4024,  0.1533, -0.0147]],\n",
      "\n",
      "         [[ 0.2703,  0.3288, -0.1088],\n",
      "          [-0.1951,  0.2897,  0.2138],\n",
      "          [-0.4334,  0.1604, -0.1183]],\n",
      "\n",
      "         [[ 0.5183,  0.1994, -0.4405],\n",
      "          [ 0.0667, -0.0579,  0.0483],\n",
      "          [ 0.0740, -0.1484, -0.1704]]]])\n",
      "conv2.bias\n",
      "tensor([ 0.1219,  0.5986,  0.0946,  0.0988,  0.4082])\n",
      "fc1.weight\n",
      "tensor([[ 0.0826, -0.0590, -0.0676,  0.0161,  0.1541, -0.1281, -0.0403,\n",
      "          0.7019,  0.0261, -0.0741,  0.1083, -0.4229, -0.0724,  0.0727,\n",
      "          0.0550, -0.1649, -0.0334, -0.0108, -0.0120, -0.1295,  0.0143,\n",
      "          0.0869,  0.0626, -0.7201, -0.0446,  0.1004,  0.0947,  0.1402,\n",
      "         -0.0280, -0.0313,  0.1114,  0.2652, -0.1956,  0.1801,  0.3914,\n",
      "         -0.0633,  0.1226,  0.5206,  0.3039,  0.0572, -0.1573, -0.1811,\n",
      "          0.2371, -0.0748,  0.2694, -0.2651, -0.0807,  0.3467, -0.2414,\n",
      "         -0.0122, -0.0059,  0.0419, -0.1165, -0.0256, -0.1381,  0.0225,\n",
      "          0.1507,  0.1811, -0.0563,  0.6277, -0.1436, -0.0546, -0.0054,\n",
      "         -0.1139, -0.0932, -0.0423,  0.0571,  0.3902, -0.1382,  0.0931,\n",
      "         -0.0550, -0.2878, -0.1171,  0.2544,  0.0131, -0.3582,  0.1410,\n",
      "         -0.1806, -0.2177,  0.0474]])\n",
      "fc1.bias\n",
      "tensor([-0.2972])\n"
     ]
    }
   ],
   "source": [
    "params = net.state_dict()\n",
    "for key, value in params.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.29721215], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['fc1.bias'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.5791,  1.1537,  1.0077,  ..., -0.0000, -0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.6774,  1.3424,  1.3536,  ..., -0.0000, -0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = net.pool0(X_test)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 2.9896,  2.7273,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0083,  0.0000,  0.0000,  0.3413],\n",
       "          [ 3.0476,  4.1616,  0.6891,  0.0000,  0.0000,  0.0000,  0.5120,\n",
       "            0.1046,  0.0506,  0.0256,  0.0559,  0.3914,  0.2587,  0.8099],\n",
       "          [ 0.4298,  0.0136,  0.0000,  0.0000,  0.0000,  0.0177,  2.2565,\n",
       "            3.5687,  2.2694,  0.0290,  0.0000,  0.6461,  0.4188,  0.5486],\n",
       "          [ 0.2837,  0.1487,  0.0131,  0.0000,  1.3816,  1.3646,  0.9308,\n",
       "            1.7003,  1.4421,  0.3033,  0.0007,  0.8213,  0.7713,  1.3598],\n",
       "          [ 0.8529,  0.3343,  0.0017,  0.0275,  3.2024,  2.9152,  3.2534,\n",
       "            1.6996,  0.0464,  0.7146,  0.3012,  2.0293,  1.7992,  1.7493],\n",
       "          [ 0.1673,  0.7290,  0.0984,  0.5467,  2.5228,  2.6183,  1.9869,\n",
       "            1.4354,  1.0777,  2.1503,  1.3492,  1.9878,  1.6343,  0.8734],\n",
       "          [ 0.0161,  1.4348,  1.2058,  1.2815,  0.0603,  0.6792,  1.7345,\n",
       "            2.1348,  1.8072,  1.8675,  1.6613,  0.0859,  0.7999,  1.3455],\n",
       "          [ 0.3000,  2.2074,  2.1229,  1.9502,  0.4755,  0.3724,  2.6843,\n",
       "            3.4154,  2.1598,  1.7008,  3.0519,  0.3541,  0.6708,  2.8422],\n",
       "          [ 0.4133,  1.9127,  3.2532,  0.5471,  0.2410,  0.0121,  0.8759,\n",
       "            2.4240,  1.9827,  0.7485,  1.0200,  1.2391,  1.2995,  2.3155],\n",
       "          [ 0.2745,  0.6818,  2.9252,  0.4011,  0.2463,  1.0568,  1.2936,\n",
       "            1.2870,  0.9294,  3.5114,  0.1068,  0.8307,  3.0491,  4.3835],\n",
       "          [ 2.0435,  1.5727,  3.7328,  0.7964,  0.7708,  4.0634,  4.0473,\n",
       "            3.1453,  1.2100,  3.6900,  0.9162,  1.0685,  2.9083,  2.2860],\n",
       "          [ 1.9500,  2.1991,  2.8368,  0.9641,  0.2934,  2.4250,  3.1760,\n",
       "            1.5339,  0.9160,  1.0116,  0.1926,  0.1993,  1.3248,  0.8825],\n",
       "          [ 0.1588,  0.3501,  0.4535,  0.4057,  0.3092,  0.6970,  0.8075,\n",
       "            0.0535,  0.0000,  0.0012,  0.0000,  0.0000,  0.1934,  0.4359],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0063,  0.0000,  0.0000,  0.0037,\n",
       "            0.0040,  0.0000,  0.0000,  0.0000,  0.0000,  0.0294,  0.2409]],\n",
       "\n",
       "         [[ 0.2551,  0.1521,  1.0925,  0.4292,  0.4260,  0.4220,  0.4233,\n",
       "            0.4220,  0.4220,  0.3655,  0.3801,  0.4761,  0.4817,  0.1976],\n",
       "          [ 1.3951,  0.6283,  0.5767,  0.4219,  0.4225,  0.4077,  0.1426,\n",
       "            0.1897,  0.2163,  0.5347,  0.4438,  0.2734,  0.6492,  0.6718],\n",
       "          [ 1.3811,  0.4942,  0.4650,  0.4220,  0.3879,  0.3896,  0.7177,\n",
       "            0.7862,  0.4550,  1.0386,  0.4482,  0.2764,  1.3480,  0.6996],\n",
       "          [ 0.5000,  1.0790,  0.7536,  0.4220,  0.0045,  0.4241,  0.8943,\n",
       "            0.4778,  1.6221,  1.2600,  0.3984,  0.2391,  0.4559,  0.1282],\n",
       "          [ 0.6931,  0.6481,  0.4890,  0.3285,  0.0043,  1.4541,  0.6257,\n",
       "            1.0865,  0.9635,  0.4744,  0.4257,  0.1041,  0.7444,  1.1130],\n",
       "          [ 0.3900,  0.1093,  0.4462,  0.2954,  1.2048,  1.2715,  1.0268,\n",
       "            1.3259,  0.9586,  0.9780,  0.8986,  1.1699,  0.9853,  0.4909],\n",
       "          [ 0.6851,  0.1770,  1.0943,  0.6269,  1.4058,  0.6678,  0.2354,\n",
       "            0.3302,  0.5760,  0.3752,  0.5382,  1.2575,  0.0176,  0.0625],\n",
       "          [ 0.9241,  0.2769,  0.6891,  0.8967,  1.2360,  1.2852,  1.1359,\n",
       "            1.4113,  1.2882,  1.4385,  1.1878,  1.5407,  0.3144,  0.5974],\n",
       "          [ 0.7890,  0.6771,  0.3834,  1.1182,  0.8158,  0.5417,  0.8053,\n",
       "            0.8920,  0.7033,  0.3378,  0.7641,  0.3991,  0.1228,  0.0506],\n",
       "          [ 1.1923,  1.3873,  0.5386,  0.9858,  0.0754,  0.0386,  0.0038,\n",
       "            0.0943,  1.1962,  0.0497,  1.0302,  0.1016,  0.3541,  1.0659],\n",
       "          [ 0.3804,  0.9137,  0.6610,  0.5658,  0.3011,  0.4385,  1.1382,\n",
       "            0.6867,  0.9642,  1.4540,  0.9100,  0.0431,  0.6687,  1.2700],\n",
       "          [ 1.1239,  1.7133,  1.2332,  0.3734,  0.3893,  1.2995,  1.8547,\n",
       "            1.2335,  0.1949,  0.8899,  0.7465,  0.6954,  0.7479,  1.0924],\n",
       "          [ 0.9216,  0.9465,  0.7271,  0.7749,  0.8257,  0.5464,  0.6337,\n",
       "            0.2127,  0.0416,  0.1603,  0.1426,  0.0834,  0.5735,  0.8440],\n",
       "          [ 0.3830,  0.4319,  0.5114,  0.4893,  0.3982,  0.4188,  0.4347,\n",
       "            0.4769,  0.2904,  0.2384,  0.2564,  0.3420,  0.4640,  0.5380]],\n",
       "\n",
       "         [[ 2.1702,  2.2878,  0.0244,  0.2833,  0.2797,  0.2821,  0.2803,\n",
       "            0.2814,  0.2814,  0.3439,  0.3796,  0.2743,  0.2182,  1.0096],\n",
       "          [ 1.9400,  3.0583,  0.3388,  0.2815,  0.2808,  0.3001,  1.4689,\n",
       "            0.4343,  0.3652,  0.2936,  0.4263,  0.9371,  0.5075,  1.3326],\n",
       "          [ 0.2968,  0.2525,  0.2433,  0.2814,  0.3263,  0.4472,  2.3125,\n",
       "            2.5293,  1.5004,  0.0079,  0.2848,  1.1917,  0.6014,  1.4204],\n",
       "          [ 0.3719,  0.2173,  0.1181,  0.2814,  2.2387,  1.1810,  0.8512,\n",
       "            1.4512,  0.9946,  0.2908,  0.2679,  1.4360,  0.7316,  1.6705],\n",
       "          [ 1.0158,  0.5207,  0.1306,  0.4435,  3.8605,  1.4904,  2.4424,\n",
       "            0.9027,  0.2748,  1.1820,  0.5417,  2.2603,  1.0093,  1.2564],\n",
       "          [ 0.5519,  1.2350,  0.3151,  0.8420,  2.0706,  1.6732,  1.6613,\n",
       "            0.9721,  0.9548,  1.7300,  0.8494,  1.5124,  1.0079,  1.1166],\n",
       "          [ 0.2257,  1.9632,  0.8900,  1.0420,  0.0429,  1.1625,  1.9613,\n",
       "            1.7556,  1.1859,  1.5770,  1.3604,  0.1124,  1.3498,  1.8427],\n",
       "          [ 0.4421,  2.4695,  1.4662,  1.2275,  0.2437,  0.6310,  2.5222,\n",
       "            2.3641,  1.1476,  1.1039,  2.4260,  0.0915,  1.1511,  2.5909],\n",
       "          [ 0.6002,  2.0583,  2.4960,  0.0594,  0.4679,  0.3041,  1.1798,\n",
       "            2.1157,  1.6296,  0.6671,  1.2535,  1.1639,  2.0827,  2.3463],\n",
       "          [ 0.0960,  1.0151,  2.6855,  0.0000,  1.0692,  1.8609,  1.2660,\n",
       "            1.2588,  1.0043,  3.3246,  0.0103,  1.7516,  3.0927,  2.9849],\n",
       "          [ 1.1915,  1.4463,  2.6349,  0.1431,  1.2786,  3.8344,  2.3315,\n",
       "            1.7104,  0.6190,  3.1381,  0.1597,  1.8315,  2.4118,  1.6204],\n",
       "          [ 1.5476,  1.6060,  2.1079,  0.6564,  0.7467,  2.2166,  1.9562,\n",
       "            0.7565,  1.0012,  1.1061,  0.0829,  0.7216,  1.6580,  0.7915],\n",
       "          [ 0.3953,  0.6228,  0.6958,  0.5047,  0.5144,  0.9552,  0.9422,\n",
       "            0.1643,  0.2168,  0.2017,  0.0028,  0.0892,  0.7278,  0.5857],\n",
       "          [ 0.2569,  0.3164,  0.3226,  0.3302,  0.3084,  0.3236,  0.3454,\n",
       "            0.3179,  0.2256,  0.2111,  0.2146,  0.2053,  0.3457,  0.5886]],\n",
       "\n",
       "         [[ 0.7351,  0.7269,  1.0738,  0.7484,  0.7540,  0.7510,  0.7515,\n",
       "            0.7510,  0.7510,  0.7389,  0.6487,  0.7743,  0.8651,  0.6306],\n",
       "          [ 4.4176,  6.3757,  2.5438,  0.7509,  0.7510,  0.7818,  0.5212,\n",
       "            0.2407,  0.2606,  0.4990,  0.9423,  0.6100,  0.3442,  0.7337],\n",
       "          [ 1.7163,  0.8167,  0.6978,  0.7510,  0.7505,  0.6558,  0.3838,\n",
       "            2.5485,  1.8010,  1.0723,  0.7546,  0.7606,  1.4689,  0.3884],\n",
       "          [ 0.4665,  0.5927,  0.8453,  0.7510,  0.2780,  0.1617,  0.9212,\n",
       "            1.3339,  2.0870,  1.8774,  0.7225,  0.3913,  0.5655,  0.1624],\n",
       "          [ 1.3897,  1.1122,  0.7739,  0.6698,  0.2463,  2.1883,  1.5936,\n",
       "            1.9164,  1.0533,  0.3008,  0.2948,  0.2808,  1.4285,  1.9512],\n",
       "          [ 0.7530,  0.8736,  0.5274,  0.4209,  1.6996,  3.4788,  1.9293,\n",
       "            1.8830,  0.2678,  0.9662,  1.4407,  1.7626,  2.4228,  1.2413],\n",
       "          [ 0.6367,  0.3865,  0.7479,  0.6793,  1.0892,  0.7602,  0.6019,\n",
       "            0.2716,  0.8707,  1.4737,  0.8903,  1.4200,  1.4257,  0.1453],\n",
       "          [ 1.1753,  0.5836,  1.0862,  1.3973,  1.2905,  0.7759,  1.2021,\n",
       "            2.5960,  2.4466,  1.6457,  1.6590,  1.4561,  0.7313,  1.1160],\n",
       "          [ 1.0081,  0.9887,  2.0585,  1.9359,  1.3487,  0.3247,  0.5200,\n",
       "            1.4299,  1.7094,  1.0091,  1.0398,  1.9208,  0.3568,  0.5164],\n",
       "          [ 0.8675,  1.1993,  1.3901,  1.4402,  0.3841,  0.1482,  0.1961,\n",
       "            0.1895,  0.6845,  1.6745,  0.7168,  1.0854,  0.2428,  2.4467],\n",
       "          [ 1.6164,  0.1193,  1.3867,  2.1717,  0.5294,  1.1400,  2.6730,\n",
       "            2.4190,  1.3959,  1.4511,  3.6297,  0.3547,  1.7007,  2.3757],\n",
       "          [ 2.1985,  2.2196,  3.5011,  2.6760,  0.3400,  1.0796,  2.8381,\n",
       "            3.1990,  1.9582,  1.6248,  2.0472,  1.0436,  2.1935,  1.6826],\n",
       "          [ 0.9786,  0.9702,  1.1615,  1.1821,  1.1577,  1.5350,  1.7636,\n",
       "            1.4961,  0.8438,  1.1615,  0.6214,  0.0462,  0.1013,  0.6508],\n",
       "          [ 0.6962,  0.7653,  0.7784,  0.8291,  0.8083,  0.7999,  0.8404,\n",
       "            0.7820,  0.8051,  0.7105,  0.6447,  0.6678,  0.7537,  1.1307]],\n",
       "\n",
       "         [[ 0.0510,  0.6798,  1.0861,  0.5818,  0.5838,  0.5847,  0.5862,\n",
       "            0.5875,  0.5875,  0.5113,  0.5124,  0.4745,  0.5642,  0.2394],\n",
       "          [ 0.0000,  0.0000,  0.2148,  0.5878,  0.5884,  0.5440,  0.1985,\n",
       "            0.5463,  0.7998,  0.5689,  0.3065,  0.2387,  1.0065,  0.3139],\n",
       "          [ 0.0000,  0.4828,  0.5563,  0.5875,  0.5292,  0.4629,  0.0000,\n",
       "            0.0000,  0.1330,  0.4308,  0.5879,  0.1646,  0.7867,  0.2400],\n",
       "          [ 0.1644,  0.3449,  0.4509,  0.5875,  0.0000,  0.0879,  0.1343,\n",
       "            0.0000,  0.0303,  0.0607,  0.6152,  0.0906,  0.1457,  0.0686],\n",
       "          [ 0.0412,  0.1113,  0.5461,  0.4873,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0747,  0.2895,  0.0926,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.3747,  0.0000,  0.0461,  0.2707,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1026],\n",
       "          [ 0.5832,  0.0000,  0.0000,  0.0000,  0.0890,  0.0677,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.1807,  0.0080,  0.0292],\n",
       "          [ 0.0948,  0.0000,  0.0000,  0.0000,  0.1789,  0.1675,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0852,  0.1474,  0.0000],\n",
       "          [ 0.1784,  0.0000,  0.0000,  0.1824,  0.2240,  0.5834,  0.3313,\n",
       "            0.0000,  0.0000,  0.4871,  0.5450,  0.0434,  0.0926,  0.0000],\n",
       "          [ 0.0522,  0.0000,  0.0000,  0.4788,  0.2405,  0.2184,  0.1174,\n",
       "            0.0102,  0.0656,  0.0000,  1.4971,  0.2373,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.2372,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.1245,  0.0798,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0273,  0.0000,  0.0000,\n",
       "            0.0543,  0.1220,  0.3066,  0.7843,  0.5052,  0.0000,  0.0000],\n",
       "          [ 0.2223,  0.1408,  0.0105,  0.0040,  0.1010,  0.0641,  0.0033,\n",
       "            0.6508,  1.3773,  1.6330,  2.1952,  1.9565,  0.4345,  0.0728],\n",
       "          [ 0.6583,  0.5834,  0.5483,  0.5275,  0.5536,  0.5587,  0.5294,\n",
       "            0.5005,  0.6053,  0.7287,  0.7063,  0.6690,  0.5857,  0.3269]]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = net.pool1(F.relu(net.conv1(mat)))\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.7245,  2.9144,  2.0041,  1.7712],\n",
       "          [ 2.3932,  1.3243,  2.3043,  1.8784],\n",
       "          [ 1.4030,  2.8169,  1.7986,  2.3987],\n",
       "          [ 1.6967,  1.3228,  1.4515,  2.0170]],\n",
       "\n",
       "         [[ 2.6577,  1.0501,  1.6945,  1.1951],\n",
       "          [ 0.7797,  1.7055,  0.6594,  0.9934],\n",
       "          [ 1.5289,  0.6554,  1.5661,  1.0234],\n",
       "          [ 1.6763,  1.5860,  1.6955,  1.1643]],\n",
       "\n",
       "         [[ 0.3246,  0.6026,  0.1709,  0.3178],\n",
       "          [ 0.4125,  0.6620,  0.0015,  0.2274],\n",
       "          [ 0.4246,  0.6517,  0.1932,  0.7214],\n",
       "          [ 0.2037,  0.8563,  0.1220,  0.2548]],\n",
       "\n",
       "         [[ 0.4498,  0.6473,  0.6233,  0.2590],\n",
       "          [ 0.4052,  1.1604,  0.7552,  1.0241],\n",
       "          [ 1.0047,  0.7187,  1.1670,  1.3284],\n",
       "          [ 0.9126,  0.9888,  0.5209,  0.2752]],\n",
       "\n",
       "         [[ 0.1560,  0.6472,  0.0675,  0.3956],\n",
       "          [ 0.5628,  0.0311,  0.0000,  0.0269],\n",
       "          [ 0.0000,  0.5598,  0.0000,  0.0000],\n",
       "          [ 0.0566,  0.2672,  0.0352,  0.5312]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = net.pool2(F.relu(net.conv2(mat)))\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7245,  2.9144,  2.0041,  1.7712,  2.3932,  1.3243,  2.3043,\n",
       "          1.8784,  1.4030,  2.8169,  1.7986,  2.3987,  1.6967,  1.3228,\n",
       "          1.4515,  2.0170,  2.6577,  1.0501,  1.6945,  1.1951,  0.7797,\n",
       "          1.7055,  0.6594,  0.9934,  1.5289,  0.6554,  1.5661,  1.0234,\n",
       "          1.6763,  1.5860,  1.6955,  1.1643,  0.3246,  0.6026,  0.1709,\n",
       "          0.3178,  0.4125,  0.6620,  0.0015,  0.2274,  0.4246,  0.6517,\n",
       "          0.1932,  0.7214,  0.2037,  0.8563,  0.1220,  0.2548,  0.4498,\n",
       "          0.6473,  0.6233,  0.2590,  0.4052,  1.1604,  0.7552,  1.0241,\n",
       "          1.0047,  0.7187,  1.1670,  1.3284,  0.9126,  0.9888,  0.5209,\n",
       "          0.2752,  0.1560,  0.6472,  0.0675,  0.3956,  0.5628,  0.0311,\n",
       "          0.0000,  0.0269,  0.0000,  0.5598,  0.0000,  0.0000,  0.0566,\n",
       "          0.2672,  0.0352,  0.5312]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = mat.view(-1, 80)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5504]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = net.fc1(mat)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.2570]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat + month_mean[2, row[1], row[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（92°W，0°）今年3月份海温（真实值为27.26599℃）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 27.5039]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.zeros((1, 2, 89, 180), dtype=np.float32)\n",
    "X_test[0, 0] = SST[-3, 0]\n",
    "X_test[0, 1] = SST[-2, 0]\n",
    "X_test = torch.from_numpy(X_test)\n",
    "\n",
    "y_fore = net(X_test) + month_mean[2, row[1], row[0]]\n",
    "y_fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.5720]])\n",
      "tensor([[ 29.1317]])\n",
      "tensor([[ 27.6299]])\n",
      "tensor([[ 29.9275]])\n",
      "tensor([[ 27.4515]])\n",
      "tensor([[ 3.9730]])\n",
      "tensor([[ 24.6470]])\n",
      "tensor([[ 19.6922]])\n",
      "tensor([[ 16.1494]])\n",
      "tensor([[ 5.9008]])\n"
     ]
    }
   ],
   "source": [
    "for row in loc:\n",
    "    y_train = SST[2:-15, :, row[1], row[0]]\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    y_valid = SST[-15:-3, :, row[1], row[0]]\n",
    "    y_valid = torch.from_numpy(y_valid)\n",
    "    \n",
    "    net = Net()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(1000):  # loop over the dataset multiple times\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        outputs_valid = net(X_valid)\n",
    "        loss_valid = criterion(outputs_valid, y_valid)\n",
    "    \n",
    "    print(net(X_test) + month_mean[2, row[1], row[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classfication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据上传到百度网盘 内涝等级识别 文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler #only can be imported above pytorch0.2.0\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "image_datasets = datasets.ImageFolder('train',\n",
    "                                      data_transforms)\n",
    "\n",
    "test_datasets = datasets.ImageFolder('test',\n",
    "                                      data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_weights_for_balanced_classes(images, nclasses):                        \n",
    "    count = [0] * nclasses\n",
    "    for item in images:\n",
    "        count[item[1]] += 1\n",
    "    weight_per_class = [0.] * nclasses\n",
    "    N = float(sum(count))\n",
    "    for i in range(nclasses):\n",
    "        weight_per_class[i] = N/float(count[i])\n",
    "    weight = [0] * len(images)\n",
    "    for idx, val in enumerate(images):\n",
    "        weight[idx] = weight_per_class[val[1]]\n",
    "    return weight\n",
    "\n",
    "weight = make_weights_for_balanced_classes(image_datasets, 5)\n",
    "\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(weight, len(weight))\n",
    "\n",
    "dataloders = torch.utils.data.DataLoader(image_datasets,\n",
    "                                         batch_size=1,\n",
    "                                         sampler = sampler,\n",
    "                                         num_workers=0)\n",
    "\n",
    "datatest = torch.utils.data.DataLoader(test_datasets,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=True)\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(25):  # loop over the dataset multiple times\n",
    "    scheduler.step()\n",
    "    i = 0\n",
    "    loss_sum = 0\n",
    "    for data in dataloders:\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_sum += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "\n",
    "            print(i, loss_sum / 1000)\n",
    "\n",
    "            loss_sum = 0\n",
    "\n",
    "    correct = np.zeros((5, 5))\n",
    "    for data in datatest:\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct[int(labels), int(predicted)] += 1\n",
    "    for row in correct:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python36\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.1513543e-05 9.9989283e-01 4.3832726e-05 1.4410913e-06 3.7497728e-07] 1\n",
      "[1.9392589e-06 9.7590164e-06 1.0727131e-05 1.8801609e-04 9.9978954e-01] 4\n",
      "[1.6476604e-05 3.4625569e-04 9.9959826e-01 3.7069316e-05 1.9144195e-06] 2\n",
      "[1.8656605e-05 2.6466485e-04 2.7656858e-04 4.3591481e-01 5.6352532e-01] 3\n",
      "[9.9962622e-01 3.5922590e-04 7.4621644e-06 5.9296272e-06 1.1686778e-06] 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler #only can be imported above pytorch0.2.0\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
    "\n",
    "test_datasets = datasets.ImageFolder('test_new',\n",
    "                                      data_transforms)\n",
    "\n",
    "datatest = torch.utils.data.DataLoader(test_datasets,\n",
    "                                         batch_size=1,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=0)\n",
    "\n",
    "net = models.resnet18(pretrained=True)\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs, 5)\n",
    "\n",
    "net.load_state_dict(torch.load('test.pkl'), strict=False)\n",
    "\n",
    "for data in datatest:\n",
    "    inputs, labels = data\n",
    "    outputs = F.softmax(net(inputs))\n",
    "    print(outputs.detach().numpy()[0], int(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
