{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "选取模型中需要的站点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 以下两个文件中存储的站点可根据自己的需求定义，示例代码提供的为2001年1月1日至2019年3月26日0-60°N，65°E-145°E\n",
    "# 文件缺失和数据大量（缺失天数大于10%）缺失的站点\n",
    "\n",
    "# 生成这两个文件的代码我找不到了，但我相信这你们来说并不难(ง •_•)ง\n",
    "\n",
    "unuse_nofile = pd.read_csv('DATA\\\\unuse_nofile.csv', low_memory=False).get_values()  # unuse_nofile.csv 存储的是文件缺失的站点\n",
    "\n",
    "unuse_nofile = [row[0] for row in unuse_nofile]\n",
    "\n",
    "unuse_lossdata = pd.read_csv('DATA\\\\unuse_lossdata.csv', low_memory=False).get_values()  # unuse_lossdata.csv 存储的是数据大量缺失的站点\n",
    "\n",
    "unuse_lossdata = [row[0] for row in unuse_lossdata]\n",
    "\n",
    "unuse = unuse_nofile + unuse_lossdata\n",
    "\n",
    "data = pd.read_csv('DATA\\\\isd-history.csv', low_memory=False)\n",
    "\n",
    "stats = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for row in data.get_values():\n",
    "\n",
    "    if row[8] < 20010101 and row[9] > 20190325:\n",
    "\n",
    "        if row[5] > 0 and row[5] < 60 and row[6] > 65 and row[6] < 145:\n",
    "            \n",
    "            if row[0].zfill(6) + '-' + str(row[1]).zfill(5) not in unuse:\n",
    "\n",
    "                stats += [[row[0].zfill(6) + '-' + str(row[1]).zfill(5), row[2], row[3], row[4], row[5], row[6], row[7]]]\n",
    "\n",
    "stats = pd.DataFrame(stats, columns=['USAF-WBAN', 'STATION NAME', 'CTRY', 'ST CALL', 'LAT', 'LON', 'ELEV(m)'])\n",
    "\n",
    "stats.to_csv('DATA\\\\stats.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](IMG/use_stats.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stats = pd.read_csv('DATA\\\\stats.csv', low_memory=False)\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "for year in range(2001, 2020):\n",
    "\n",
    "    for usaf_wban in stats['USAF-WBAN'].get_values():\n",
    "\n",
    "        try:\n",
    "\n",
    "            copyfile('GSOD\\\\gsod_' + str(year) + '\\\\' + usaf_wban + '-' + str(year) + '.op.gz', 'GSOD\\\\new_data\\\\' + usaf_wban + '-' + str(year) + '.op.gz')\n",
    "            # 把挑选的文件转移到一个新的文件夹（这一步其实是多余的）\n",
    "            # GSOD文件在网盘，没有传到Github上来\n",
    "        except Exception:\n",
    "\n",
    "            print(usaf_wban, year)  # 如果有报错说明该文件缺失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "date0 = datetime.datetime.strptime('20010101', \"%Y%m%d\")\n",
    "\n",
    "def line2desc(data):\n",
    "\n",
    "    stn = data[:6]\n",
    "    wban = data[7:12]\n",
    "    date = (datetime.datetime.strptime(data[14:22], \"%Y%m%d\") - date0).days\n",
    "    \n",
    "    temp = float(data[24:30])\n",
    "    if temp == 9999.9:\n",
    "        temp = np.nan\n",
    "        \n",
    "    dewp = float(data[35:41])\n",
    "    if dewp == 9999.9:\n",
    "        dewp = np.nan\n",
    "\n",
    "    slp = float(data[46:52])\n",
    "    if slp == 9999.9:\n",
    "        slp = np.nan\n",
    "\n",
    "    stp = float(data[57:63])\n",
    "    if stp == 9999.9:\n",
    "        stp = np.nan\n",
    "\n",
    "    MAX = float(data[102:108])\n",
    "    if MAX == 9999.9:\n",
    "        MAX = np.nan\n",
    "\n",
    "    MIN = float(data[110:116])\n",
    "    if MIN == 9999.9:\n",
    "        MIN = np.nan\n",
    "\n",
    "    prcp = float(data[118:123])\n",
    "    if prcp == 99.99:\n",
    "        prcp = np.nan\n",
    "\n",
    "    return [stn + '-' + wban, date, temp, dewp, slp, stp, MAX, MIN, prcp]\n",
    "\n",
    "folder = 'GSOD\\\\new_data'\n",
    "\n",
    "files = os.listdir(folder)\n",
    "\n",
    "total = np.zeros((6574, 5579)) + np.nan\n",
    "\n",
    "n = 0\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    j = n // 18  # 两个站点之间相隔18个文件，19年的数据不加入\n",
    "\n",
    "    year = int(file[13:17])\n",
    "\n",
    "    if year == 2019:\n",
    "\n",
    "        continue\n",
    "\n",
    "    data_temp = pd.read_csv(folder + '\\\\' + file, low_memory=False).get_values()  # 读取每个站点每年的数据\n",
    "\n",
    "    for row in data_temp:\n",
    "\n",
    "        desc = line2desc(row[0])  # 将一行数据转化为需要的数据\n",
    "\n",
    "        line = np.array(desc[2:])\n",
    "\n",
    "        total[desc[1], j * 7:j * 7 + 7] = line  # 每7列一个站点，desc[1]是从2001年1月1日至数据记录时的天数，也就是在矩阵中的行数\n",
    "\n",
    "    n += 1\n",
    "\n",
    "use_col = []\n",
    "\n",
    "for j in range(5579):\n",
    "\n",
    "    if np.sum(np.isnan(total[:, j])) < 657:  # 选取缺失数据小于10%的变量\n",
    "\n",
    "        use_col += [j]\n",
    "\n",
    "total = total[:, use_col]\n",
    "\n",
    "np.save('total_used.npy', total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
