{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "f = netCDF4.Dataset('D:\\\\sst.mnmean.nc')  # ftp://ftp.cdc.noaa.gov/Datasets/noaa.ersst.v5/sst.mnmean.nc\n",
    "SST = f.variables['sst'][-1203:, :, :].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = (134, 44)  # 134, 44 表示（134 * 2）°E→92°W, （88 - 44 * 2）°N→0°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = SST > -2  # 1表示海洋，0表示陆地\n",
    "A = np.average(A, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 44 : 5255\n"
     ]
    }
   ],
   "source": [
    "new_SST = np.zeros((len(SST), int(np.sum(A))))  # 合并SST数据从一个三维数组到一个二维数组\n",
    "\n",
    "s = 0\n",
    "\n",
    "for i in range(89):\n",
    "    for j in range(180):\n",
    "        if A[i, j] == 1:\n",
    "            if (j, i) == loc:\n",
    "                print(j, i, ':', s)\n",
    "            new_SST[:, s] += SST[:, i, j]\n",
    "            s += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,   12,   24,   36,   48,   60,   72,   84,   96,  108,  120,\n",
       "        132,  144,  156,  168,  180,  192,  204,  216,  228,  240,  252,\n",
       "        264,  276,  288,  300,  312,  324,  336,  348,  360,  372,  384,\n",
       "        396,  408,  420,  432,  444,  456,  468,  480,  492,  504,  516,\n",
       "        528,  540,  552,  564,  576,  588,  600,  612,  624,  636,  648,\n",
       "        660,  672,  684,  696,  708,  720,  732,  744,  756,  768,  780,\n",
       "        792,  804,  816,  828,  840,  852,  864,  876,  888,  900,  912,\n",
       "        924,  936,  948,  960,  972,  984,  996, 1008, 1020, 1032, 1044,\n",
       "       1056, 1068, 1080, 1092, 1104, 1116, 1128, 1140, 1152, 1164, 1176,\n",
       "       1188])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_mean = np.zeros((12, int(np.sum(A))))\n",
    "month_s = np.arange(0, 1200, 12)\n",
    "month_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.84811632, 26.15498543, 26.67061384, 26.13181588, 25.0056647 ,\n",
       "       23.89235374, 22.99094383, 22.40314257, 22.35578517, 22.64520766,\n",
       "       22.97098622, 23.55253011])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    month_mean[i] = np.copy(np.average(new_SST[month_s[:95] + i, :], axis = 0))\n",
    "month_mean[:, 5255]  # 波罗的海某处海域1919年至2014年95年月平均海温"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(12):\n",
    "    new_SST[month_s + i, :] -= month_mean[i]\n",
    "for i in range(3):\n",
    "    new_SST[1200 + i, :] -= month_mean[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9203976374519192"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=100)  # 设置PCA想要降到的维数\n",
    "\n",
    "pca.fit(new_SST[:1140])\n",
    "\n",
    "np.sum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_SST @ pca.components_.T\n",
    "\n",
    "X_std = np.std(X[:1140], axis = 0)\n",
    "X /= X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:1139]\n",
    "X_valid = X[1139:1199]\n",
    "X_test = X[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = new_SST[1:1140, 5255]\n",
    "y_valid = new_SST[1140:1200, 5255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "X_test = torch.from_numpy(X_test.reshape(1, 100)).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(len(y_train), 1)).float()\n",
    "y_valid = torch.from_numpy(y_valid.reshape(len(y_valid), 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from adabound import AdaBound\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 3)\n",
    "        self.fc2 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdaBound(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0736862421035767 1.9411107301712036\n",
      "1001 0.11922675371170044 0.5181803107261658\n",
      "2001 0.11572258919477463 0.4422978162765503\n",
      "3001 0.11484316736459732 0.4524969756603241\n",
      "4001 0.11483649164438248 0.4530077576637268\n",
      "5001 0.11483722925186157 0.4530792236328125\n",
      "6001 0.11483823508024216 0.452997624874115\n",
      "7001 0.11483677476644516 0.4530576467514038\n",
      "8001 0.1148369088768959 0.4529978632926941\n",
      "9001 0.11483655124902725 0.45295655727386475\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        outputs = net(X_valid)\n",
    "        loss_valid = criterion(outputs, y_valid)\n",
    "        print(epoch + 1, loss.item(), loss_valid.item())\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.193620695879584 25.375490709355002\n",
      "25.725605010986328 26.61388871073723\n",
      "26.790624619314546 26.78163404841172\n",
      "26.549350738211682 26.296852737351468\n",
      "26.679452894863328 25.08423972004338\n",
      "26.143993345059847 24.70031222418735\n",
      "24.624321022786592 24.6988294513602\n",
      "23.667221065571432 24.155559774448996\n",
      "23.38800243327492 23.606899895166094\n",
      "23.729892743261235 23.508764637143987\n",
      "24.111202208619368 24.06691154680754\n",
      "24.508861539865794 24.04925975015289\n",
      "25.268852248003608 24.726700275352126\n",
      "26.084409713745117 26.083786517381668\n",
      "27.0227508403753 26.367520079800958\n",
      "27.623594253941587 26.342915892287305\n",
      "27.091974376377305 26.014590262111863\n",
      "26.963388410367465 25.941001382626986\n",
      "26.370748439588045 25.264405885495638\n",
      "24.83215152840865 25.128507967999106\n",
      "25.315359153245623 24.015954651330645\n",
      "25.57662965122022 24.819972050817388\n",
      "26.050239650826704 25.486461011986982\n",
      "26.717212734724345 25.514400897527995\n",
      "27.22409240823043 26.763605400135642\n",
      "27.63623046875 27.909051537513733\n",
      "28.250402406642312 27.841722921321267\n",
      "26.395015716239026 27.103343575879148\n",
      "25.185480116543015 25.415003387865266\n",
      "24.233331677474474 24.515846219815707\n",
      "22.58970070795009 23.29955692008922\n",
      "22.11909675221694 21.799159642269736\n",
      "22.7046413500058 21.650046386216815\n",
      "22.521661756070035 22.342113894851583\n",
      "22.733989714007627 22.667892454486143\n",
      "23.454322813059154 23.351626215483012\n",
      "25.72358129840148 25.47692100625289\n",
      "27.548276901245117 26.837697505950928\n",
      "28.18790812868821 27.319280699679727\n",
      "27.44452664224725 26.927788108273557\n",
      "25.330526350673875 25.700553296741685\n",
      "23.95768737510631 24.30992835477779\n",
      "22.924203874327635 23.07657066897342\n",
      "22.215806957295065 22.770849969198828\n",
      "21.495750405286486 21.50971189925545\n",
      "22.25970841708936 21.478756201894658\n",
      "22.08606150589491 22.805985478978407\n",
      "22.321928082014384 23.128536043669047\n",
      "23.574132963230735 24.398720278551703\n",
      "25.499608993530273 25.851891666650772\n",
      "25.890855804870004 26.63462592739808\n",
      "25.591907530709317 26.360390066786817\n",
      "24.898065565761765 25.283894507822236\n",
      "24.169143673934435 24.807202783383822\n",
      "23.410678872622942 24.005245843686556\n",
      "22.73114394765151 23.040760632565146\n",
      "22.797069557403262 22.904557980989154\n",
      "23.5951309329585 23.10815898838796\n",
      "24.45730015478636 23.387327252249968\n",
      "25.257026730085673 25.045321641470256\n",
      "\n",
      "\n",
      "0.45298558473587036\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X_valid)\n",
    "loss = criterion(outputs, y_valid)\n",
    "\n",
    "for i in range(60):\n",
    "    print(y_valid[i].item() + month_mean[i % 12, 5255], outputs[i].item() + month_mean[i % 12, 5255])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（92°W，0°）今年3月份海温（真实值为27.26599℃）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.77191925048828"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = net(X_test) + month_mean[2, 5255]\n",
    "y_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用连续六个月预测第七个月的海温，依旧使用NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 6\n",
    "\n",
    "X_train = np.zeros((1140 - seq, seq * 100), dtype = np.float32)\n",
    "X_valid = np.zeros((60, seq * 100), dtype = np.float32)\n",
    "X_test = np.zeros((1, seq * 100), dtype = np.float32)\n",
    "\n",
    "for i in range(6):\n",
    "    X_train[:, i * 100:i * 100 + 100] = X[i:1140 - seq + i]\n",
    "    X_valid[:, i * 100:i * 100 + 100] = X[1140 - seq + i:1200 - seq + i]\n",
    "    X_test[:, i * 100:i * 100 + 100] = X[- (seq + 1) + i]\n",
    "\n",
    "y_train = new_SST[seq:1140, 5255]\n",
    "y_valid = new_SST[1140:1200, 5255]\n",
    "\n",
    "import torch\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(len(y_train), 1)).float()\n",
    "y_valid = torch.from_numpy(y_valid.reshape(len(y_valid), 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from adabound import AdaBound\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(600, 3)\n",
    "        self.fc2 = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdaBound(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.6621829271316528 3.464352607727051\n",
      "1001 0.14149276912212372 1.886434555053711\n",
      "2001 0.14045922458171844 1.882771372795105\n",
      "3001 0.14045710861682892 1.8813800811767578\n",
      "4001 0.1404571384191513 1.8810398578643799\n",
      "5001 0.1404571384191513 1.880966305732727\n",
      "6001 0.14045710861682892 1.8809258937835693\n",
      "7001 0.1404571235179901 1.880924940109253\n",
      "8001 0.1404571384191513 1.8809261322021484\n",
      "9001 0.14045709371566772 1.8809269666671753\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        outputs = net(X_valid)\n",
    "        loss_valid = criterion(outputs, y_valid)\n",
    "        print(epoch + 1, loss.item(), loss_valid.item())\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.193620695879584 26.21408490758193\n",
      "25.725605010986328 27.24207615852356\n",
      "26.790624619314546 27.251985744426126\n",
      "26.549350738211682 25.954872578068784\n",
      "26.679452894863328 25.64826047295018\n",
      "26.143993345059847 23.74592682436893\n",
      "24.624321022786592 23.87535569981525\n",
      "23.667221065571432 23.536782618572836\n",
      "23.38800243327492 23.065786160920794\n",
      "23.729892743261235 22.386827839048284\n",
      "24.111202208619368 24.127846805672895\n",
      "24.508861539865794 25.03056293537742\n",
      "25.268852248003608 26.38736371617568\n",
      "26.084409713745117 26.498181343078613\n",
      "27.0227508403753 26.509788350055093\n",
      "27.623594253941587 25.57552430002313\n",
      "27.091974376377305 25.5663887249796\n",
      "26.963388410367465 24.552252081193423\n",
      "26.370748439588045 23.856938639440035\n",
      "24.83215152840865 23.495555635502463\n",
      "25.315359153245623 23.812286295388873\n",
      "25.57662965122022 24.251610291631597\n",
      "26.050239650826704 24.284673182587873\n",
      "26.717212734724345 24.731226978803935\n",
      "27.22409240823043 26.45451895814193\n",
      "27.63623046875 27.761388063430786\n",
      "28.250402406642312 27.0550398387407\n",
      "26.395015716239026 26.580763309880307\n",
      "25.185480116543015 25.03108382099553\n",
      "24.233331677474474 23.3623845250983\n",
      "22.58970070795009 22.14605585650394\n",
      "22.11909675221694 20.9806660376097\n",
      "22.7046413500058 21.70697716662758\n",
      "22.521661756070035 20.961080086858647\n",
      "22.733989714007627 21.03106769762541\n",
      "23.454322813059154 20.735152302290263\n",
      "25.72358129840148 23.626643582394248\n",
      "27.548276901245117 26.703112602233887\n",
      "28.18790812868821 26.67364724058854\n",
      "27.44452664224725 26.68510374395471\n",
      "25.330526350673875 26.43150377148076\n",
      "23.95768737510631 25.360727992810702\n",
      "22.924203874327635 23.29216865614841\n",
      "22.215806957295065 22.531382437756186\n",
      "21.495750405286486 22.843443669770892\n",
      "22.25970841708936 23.052044642599004\n",
      "22.08606150589491 24.55960044107939\n",
      "22.321928082014384 25.056520877386394\n",
      "23.574132963230735 25.56748120408309\n",
      "25.499608993530273 27.132454335689545\n",
      "25.890855804870004 26.872633890101785\n",
      "25.591907530709317 26.961814373417905\n",
      "24.898065565761765 25.916315673526963\n",
      "24.169143673934435 24.74964949206302\n",
      "23.410678872622942 23.346042075910066\n",
      "22.73114394765151 22.934554215481405\n",
      "22.797069557403262 22.23933390567177\n",
      "23.5951309329585 22.049658787877934\n",
      "24.45730015478636 22.279975263695967\n",
      "25.257026730085673 23.73223978092796\n",
      "\n",
      "\n",
      "1.8809268474578857\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X_valid)\n",
    "loss = criterion(outputs, y_valid)\n",
    "\n",
    "for i in range(60):\n",
    "    print(y_valid[i].item() + month_mean[i % 12, 5255], outputs[i].item() + month_mean[i % 12, 5255])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（92°W，0°）今年3月份海温（真实值为27.26599℃）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.486730575561523"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = net(X_test) + month_mean[2, 5255]\n",
    "y_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Rnn(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Rnn, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=100,\n",
    "            hidden_size=2,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x, None)\n",
    "        x = self.fc(x[:, -1, :])  # 只计算最后一个步长的输出\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 6\n",
    "\n",
    "X_train = np.zeros((1140 - seq, seq, 100), dtype = np.float32)\n",
    "X_valid = np.zeros((60, seq, 100), dtype = np.float32)\n",
    "X_test = np.zeros((1, seq, 100), dtype = np.float32)\n",
    "\n",
    "for i in range(seq):\n",
    "    X_train[:, i] = X[i:1140 - seq + i]\n",
    "    X_valid[:, i] = X[1140 - seq + i:1200 - seq + i]\n",
    "    X_test[:, i] = X[- (seq + 1) + i]\n",
    "\n",
    "y_train = new_SST[seq:1140, 5255]\n",
    "y_valid = new_SST[1140:1200, 5255]\n",
    "\n",
    "import torch\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(len(y_train), 1)).float()\n",
    "y_valid = torch.from_numpy(y_valid.reshape(len(y_valid), 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Rnn()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdaBound(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.8713352680206299 3.143311023712158\n",
      "1001 0.827667236328125 1.3726789951324463\n",
      "2001 0.36556875705718994 0.6758120656013489\n",
      "3001 0.20847921073436737 0.40724092721939087\n",
      "4001 0.16274335980415344 0.33378124237060547\n",
      "5001 0.15482378005981445 0.3390403091907501\n",
      "6001 0.1502528041601181 0.33562931418418884\n",
      "7001 0.14719653129577637 0.33005768060684204\n",
      "8001 0.14609143137931824 0.32994475960731506\n",
      "9001 0.1455148458480835 0.3327111601829529\n",
      "10001 0.14452959597110748 0.33963245153427124\n",
      "11001 0.14340758323669434 0.34315335750579834\n",
      "12001 0.14204926788806915 0.3454020917415619\n",
      "13001 0.14066240191459656 0.3488912284374237\n",
      "14001 0.1402275562286377 0.3485538363456726\n",
      "15001 0.13993574678897858 0.3476327657699585\n",
      "16001 0.13963928818702698 0.3467995226383209\n",
      "17001 0.13899187743663788 0.34561482071876526\n",
      "18001 0.13852889835834503 0.34731075167655945\n",
      "19001 0.13829493522644043 0.34728753566741943\n",
      "20001 0.13810822367668152 0.3471439480781555\n",
      "21001 0.13794583082199097 0.34722191095352173\n",
      "22001 0.1377997100353241 0.34722810983657837\n",
      "23001 0.1376640349626541 0.34725624322891235\n",
      "24001 0.13753628730773926 0.34730809926986694\n",
      "25001 0.13741566240787506 0.34736427664756775\n",
      "26001 0.1373014599084854 0.3474125266075134\n",
      "27001 0.13719268143177032 0.3474459946155548\n",
      "28001 0.1370888650417328 0.34746474027633667\n",
      "29001 0.13698960840702057 0.34747031331062317\n",
      "30001 0.13689452409744263 0.3474668860435486\n",
      "31001 0.1368030458688736 0.3474578261375427\n",
      "32001 0.13671521842479706 0.3474477529525757\n",
      "33001 0.13663069903850555 0.34743982553482056\n",
      "34001 0.1365489512681961 0.3474370241165161\n",
      "35001 0.13646996021270752 0.3474419414997101\n",
      "36001 0.13639353215694427 0.3474559783935547\n",
      "37001 0.1363193839788437 0.3474796414375305\n",
      "38001 0.13624750077724457 0.3475145995616913\n",
      "39001 0.13617756962776184 0.3475603759288788\n",
      "40001 0.13610979914665222 0.347616583108902\n",
      "41001 0.13604341447353363 0.3476839065551758\n",
      "42001 0.13597895205020905 0.34776198863983154\n",
      "43001 0.13591603934764862 0.3478497266769409\n",
      "44001 0.13585463166236877 0.3479471206665039\n",
      "45001 0.13579484820365906 0.34805381298065186\n",
      "46001 0.13573643565177917 0.3481687605381012\n",
      "47001 0.13567925989627838 0.3482912480831146\n",
      "48001 0.13562345504760742 0.34842073917388916\n",
      "49001 0.13556896150112152 0.3485569953918457\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50000):\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        outputs = net(X_valid)\n",
    "        loss_valid = criterion(outputs, y_valid)\n",
    "        print(epoch + 1, loss.item(), loss_valid.item())\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.193620695879584 24.971479340603477\n",
      "25.725605010986328 26.54998779296875\n",
      "26.790624619314546 25.9322690524553\n",
      "26.549350738211682 26.103351801320127\n",
      "26.679452894863328 25.29735934608861\n",
      "26.143993345059847 25.654691544332003\n",
      "24.624321022786592 24.72461000994632\n",
      "23.667221065571432 23.92221295457137\n",
      "23.38800243327492 23.459651627038653\n",
      "23.729892743261235 23.71031225982465\n",
      "24.111202208619368 24.258329717736494\n",
      "24.508861539865794 24.540400145555797\n",
      "25.268852248003608 26.202216311504966\n",
      "26.084409713745117 26.252562880516052\n",
      "27.0227508403753 26.501388148257607\n",
      "27.623594253941587 26.47641679613214\n",
      "27.091974376377305 26.570494531330308\n",
      "26.963388410367465 26.06452247218082\n",
      "26.370748439588045 25.877356448926424\n",
      "24.83215152840865 25.680879231503134\n",
      "25.315359153245623 24.052516974900897\n",
      "25.57662965122022 25.544136775167363\n",
      "26.050239650826704 25.870408861260664\n",
      "26.717212734724345 26.72887164166099\n",
      "27.22409240823043 28.03124229531539\n",
      "27.63623046875 28.05290412902832\n",
      "28.250402406642312 27.82211120505082\n",
      "26.395015716239026 27.362424820347837\n",
      "25.185480116543015 24.59251165264531\n",
      "24.233331677474474 23.642926898755526\n",
      "22.58970070795009 23.471954861440157\n",
      "22.11909675221694 21.289051528980856\n",
      "22.7046413500058 22.274260081742938\n",
      "22.521661756070035 22.77252591911115\n",
      "22.733989714007627 22.930536715607893\n",
      "23.454322813059154 23.478272853399577\n",
      "25.72358129840148 25.07730321507705\n",
      "27.548276901245117 27.226488947868347\n",
      "28.18790812868821 27.808836296985024\n",
      "27.44452664224725 27.498283356114438\n",
      "25.330526350673875 26.402592061695298\n",
      "23.95768737510631 24.20368787363956\n",
      "22.924203874327635 23.15267638281772\n",
      "22.215806957295065 22.789961453487997\n",
      "21.495750405286486 21.96613804290169\n",
      "22.25970841708936 22.152024400861638\n",
      "22.08606150589491 23.03791472158934\n",
      "22.321928082014384 22.64511793663627\n",
      "23.574132963230735 24.36017183881057\n",
      "25.499608993530273 24.96064603328705\n",
      "25.890855804870004 26.347607091853494\n",
      "25.591907530709317 25.507330745144895\n",
      "24.898065565761765 24.7603265034525\n",
      "24.169143673934435 23.629719224729037\n",
      "23.410678872622942 23.766051569737886\n",
      "22.73114394765151 22.858803745319968\n",
      "22.797069557403262 22.649112858270342\n",
      "23.5951309329585 22.80407549205579\n",
      "24.45730015478636 23.8507539912274\n",
      "25.257026730085673 25.306093631292644\n",
      "\n",
      "\n",
      "0.3428919017314911\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X_valid)\n",
    "loss = criterion(outputs, y_valid)\n",
    "\n",
    "for i in range(60):\n",
    "    print(y_valid[i].item() + month_mean[i % 12, 5255], outputs[i].item() + month_mean[i % 12, 5255])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（92°W，0°）今年3月份海温（真实值为27.26599℃）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.55971908569336"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = net(X_test) + month_mean[2, 5255]\n",
    "y_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改RNN，将损失函数的计算方案改为对RNN的全部输出做计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Rnn(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Rnn, self).__init__()\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=100,\n",
    "            hidden_size=2,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x, None)\n",
    "        outs = []\n",
    "        for time_step in range(x.size(1)):\n",
    "            outs.append(self.fc(x[:, time_step, :]))  # 计算6个步长全部的输出\n",
    "        return torch.stack(outs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 6\n",
    "\n",
    "X_train = np.zeros((1140 - seq, seq, 100), dtype = np.float32)\n",
    "X_valid = np.zeros((60, seq, 100), dtype = np.float32)\n",
    "X_test = np.zeros((1, seq, 100), dtype = np.float32)\n",
    "\n",
    "for i in range(seq):\n",
    "    X_train[:, i] = X[i:1140 - seq + i]\n",
    "    X_valid[:, i] = X[1140 - seq + i:1200 - seq + i]\n",
    "    X_test[:, i] = X[- (seq + 1) + i]\n",
    "\n",
    "y_train = np.zeros((1140 - seq, seq, 1), dtype = np.float32)\n",
    "y_valid = np.zeros((60, seq, 1), dtype = np.float32)   \n",
    "\n",
    "for i in range(seq):\n",
    "    y_train[:, i, 0] = new_SST[i + 1:1140 - seq + i + 1, 5255]\n",
    "    y_valid[:, i, 0] = new_SST[1140 - seq + i + 1:1200 - seq + i + 1, 5255]\n",
    "\n",
    "import torch\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_valid = torch.from_numpy(y_valid).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Rnn()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdaBound(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.5482722520828247 2.123746633529663\n",
      "1001 0.38158518075942993 1.086923599243164\n",
      "2001 0.1753682643175125 0.35406428575515747\n",
      "3001 0.16112695634365082 0.3336654305458069\n",
      "4001 0.15865999460220337 0.3256247341632843\n",
      "5001 0.15659010410308838 0.32952776551246643\n",
      "6001 0.15511101484298706 0.3353109657764435\n",
      "7001 0.1533314287662506 0.3444243371486664\n",
      "8001 0.15203750133514404 0.35505107045173645\n",
      "9001 0.1501304805278778 0.36284497380256653\n",
      "10001 0.14895951747894287 0.3647443950176239\n",
      "11001 0.14830711483955383 0.36568397283554077\n",
      "12001 0.1473568230867386 0.3679659068584442\n",
      "13001 0.1459105759859085 0.3682037889957428\n",
      "14001 0.1454010307788849 0.3651854693889618\n",
      "15001 0.1451156884431839 0.36486977338790894\n",
      "16001 0.14492495357990265 0.36540281772613525\n",
      "17001 0.14475223422050476 0.36573970317840576\n",
      "18001 0.14453986287117004 0.3655436635017395\n",
      "19001 0.14430946111679077 0.3651895225048065\n",
      "20001 0.14410404860973358 0.3649638593196869\n",
      "21001 0.14391417801380157 0.3648534119129181\n",
      "22001 0.14375931024551392 0.3650159537792206\n",
      "23001 0.14362291991710663 0.36511680483818054\n",
      "24001 0.14349494874477386 0.3651059865951538\n",
      "25001 0.14337480068206787 0.365045428276062\n",
      "26001 0.1432635486125946 0.36496785283088684\n",
      "27001 0.1431599259376526 0.36487236618995667\n",
      "28001 0.14306259155273438 0.3647569417953491\n",
      "29001 0.14297039806842804 0.3646237254142761\n",
      "30001 0.14288249611854553 0.364480584859848\n",
      "31001 0.1427989900112152 0.3643305003643036\n",
      "32001 0.1427195817232132 0.3641746938228607\n",
      "33001 0.1426430493593216 0.36401230096817017\n",
      "34001 0.14257031679153442 0.36384549736976624\n",
      "35001 0.14249961078166962 0.3636695444583893\n",
      "36001 0.14243192970752716 0.363485723733902\n",
      "37001 0.14236637949943542 0.36329397559165955\n",
      "38001 0.1423037052154541 0.36309289932250977\n",
      "39001 0.14224232733249664 0.3628862500190735\n",
      "40001 0.14218354225158691 0.3626735210418701\n",
      "41001 0.14212654531002045 0.3624579906463623\n",
      "42001 0.14207148551940918 0.3622426390647888\n",
      "43001 0.14201824367046356 0.362027108669281\n",
      "44001 0.14196737110614777 0.36181673407554626\n",
      "45001 0.14191658794879913 0.3616122901439667\n",
      "46001 0.14186802506446838 0.3614155650138855\n",
      "47001 0.1418202519416809 0.3612256646156311\n",
      "48001 0.14177507162094116 0.36104556918144226\n",
      "49001 0.14173072576522827 0.36087268590927124\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50000):\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        outputs = net(X_valid)\n",
    "        loss_valid = criterion(outputs, y_valid)\n",
    "        print(epoch + 1, loss.item(), loss_valid.item())\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.193620695879584 24.970108314564353\n",
      "25.725605010986328 26.76147896051407\n",
      "26.790624619314546 26.21222157854783\n",
      "26.549350738211682 25.907193749829343\n",
      "26.679452894863328 25.637078820404252\n",
      "26.143993345059847 25.134251561917758\n",
      "24.624321022786592 25.06894914225528\n",
      "23.667221065571432 23.574892993977194\n",
      "23.38800243327492 23.335128941034014\n",
      "23.729892743261235 24.219134700925725\n",
      "24.111202208619368 24.63671669207121\n",
      "24.508861539865794 24.64641064217216\n",
      "25.268852248003608 25.50362019162429\n",
      "26.084409713745117 26.523492455482483\n",
      "27.0227508403753 26.14056654352891\n",
      "27.623594253941587 26.231266349240354\n",
      "27.091974376377305 26.32572460049077\n",
      "26.963388410367465 25.928559270657992\n",
      "26.370748439588045 25.505715766705965\n",
      "24.83215152840865 25.44663536172164\n",
      "25.315359153245623 24.83968619296425\n",
      "25.57662965122022 25.359886897237676\n",
      "26.050239650826704 25.8259395047238\n",
      "26.717212734724345 26.219675121809306\n",
      "27.22409240823043 27.62012807946456\n",
      "27.63623046875 28.200563430786133\n",
      "28.250402406642312 27.87309964079606\n",
      "26.395015716239026 27.153530805989316\n",
      "25.185480116543015 24.85886084907933\n",
      "24.233331677474474 23.539775934972262\n",
      "22.58970070795009 22.766015210904573\n",
      "22.11909675221694 21.601306911518698\n",
      "22.7046413500058 22.04797319362038\n",
      "22.521661756070035 22.31122196975507\n",
      "22.733989714007627 22.7627892180493\n",
      "23.454322813059154 22.918114123846355\n",
      "25.72358129840148 24.877039953282004\n",
      "27.548276901245117 26.86285698413849\n",
      "28.18790812868821 27.635098651835794\n",
      "27.44452664224725 27.237976759358457\n",
      "25.330526350673875 26.486407159504136\n",
      "23.95768737510631 24.690095332421755\n",
      "22.924203874327635 23.56825653628299\n",
      "22.215806957295065 22.374854084065085\n",
      "21.495750405286486 22.400374927018817\n",
      "22.25970841708936 22.298479569585698\n",
      "22.08606150589491 22.925106017213118\n",
      "22.321928082014384 22.98604243805534\n",
      "23.574132963230735 23.796573682835227\n",
      "25.499608993530273 24.820736527442932\n",
      "25.890855804870004 26.599532560298318\n",
      "25.591907530709317 25.283554404660276\n",
      "24.898065565761765 24.81444108360692\n",
      "24.169143673934435 23.77745827750156\n",
      "23.410678872622942 23.51203576640079\n",
      "22.73114394765151 22.668743129780417\n",
      "22.797069557403262 22.596624769662554\n",
      "23.5951309329585 23.071053398282903\n",
      "24.45730015478636 23.912278620820295\n",
      "25.257026730085673 25.154808459783855\n",
      "\n",
      "\n",
      "0.3607104420661926\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X_valid)\n",
    "loss = criterion(outputs, y_valid)\n",
    "\n",
    "for i in range(60):\n",
    "    print(y_valid[i][-1].item() + month_mean[i % 12, 5255], outputs[i][-1].item() + month_mean[i % 12, 5255])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（92°W，0°）今年3月份海温（真实值为27.26599℃）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.78188705444336"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = net(X_test)[-1, -1] + month_mean[2, 5255]\n",
    "y_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class lstm(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(lstm, self).__init__()\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=100,\n",
    "            hidden_size=2,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x, None)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = lstm()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdaBound(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 6\n",
    "\n",
    "X_train = np.zeros((1140 - seq, seq, 100), dtype = np.float32)\n",
    "X_valid = np.zeros((60, seq, 100), dtype = np.float32)\n",
    "X_test = np.zeros((1, seq, 100), dtype = np.float32)\n",
    "\n",
    "for i in range(seq):\n",
    "    X_train[:, i] = X[i:1140 - seq + i]\n",
    "    X_valid[:, i] = X[1140 - seq + i:1200 - seq + i]\n",
    "    X_test[:, i] = X[- (seq + 1) + i]\n",
    "\n",
    "y_train = new_SST[seq:1140, 5255]\n",
    "y_valid = new_SST[1140:1200, 5255]\n",
    "\n",
    "import torch\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_valid = torch.from_numpy(X_valid).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "y_train = torch.from_numpy(y_train.reshape(len(y_train), 1)).float()\n",
    "y_valid = torch.from_numpy(y_valid.reshape(len(y_valid), 1)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.3009282350540161 1.446370244026184\n",
      "1001 0.9506367444992065 1.7115427255630493\n",
      "2001 0.7413881421089172 1.796886682510376\n",
      "3001 0.5693593621253967 1.839682698249817\n",
      "4001 0.43132254481315613 1.6995794773101807\n",
      "5001 0.3307509422302246 1.6118377447128296\n",
      "6001 0.24793072044849396 1.6019963026046753\n",
      "7001 0.19230233132839203 1.6059205532073975\n",
      "8001 0.14692556858062744 1.5775210857391357\n",
      "9001 0.11521155387163162 1.6153767108917236\n",
      "10001 0.09273379296064377 1.3916842937469482\n",
      "11001 0.07819138467311859 1.531123399734497\n",
      "12001 0.06656265258789062 1.5809093713760376\n",
      "13001 0.055427614599466324 1.5266815423965454\n",
      "14001 0.0465288944542408 1.5292026996612549\n",
      "15001 0.04102608188986778 1.6938410997390747\n",
      "16001 0.03762657940387726 1.7657458782196045\n",
      "17001 0.0353761650621891 1.8386359214782715\n",
      "18001 0.03308688476681709 1.9795353412628174\n",
      "19001 0.03135392442345619 2.11124849319458\n",
      "20001 0.030026959255337715 2.14719557762146\n",
      "21001 0.028564903885126114 2.2290260791778564\n",
      "22001 0.026529015973210335 2.229907274246216\n",
      "23001 0.025150125846266747 2.24360728263855\n",
      "24001 0.02428053878247738 2.259359121322632\n",
      "25001 0.02348172478377819 2.3516361713409424\n",
      "26001 0.022984560579061508 2.3821511268615723\n",
      "27001 0.022434500977396965 2.3900885581970215\n",
      "28001 0.021776936948299408 2.3764336109161377\n",
      "29001 0.021399790421128273 2.3727877140045166\n",
      "30001 0.021044369786977768 2.3964874744415283\n",
      "31001 0.020745784044265747 2.4040133953094482\n",
      "32001 0.02050206996500492 2.417954444885254\n",
      "33001 0.02028670348227024 2.4410786628723145\n",
      "34001 0.020100615918636322 2.460665464401245\n",
      "35001 0.01995794288814068 2.470475435256958\n",
      "36001 0.01984710432589054 2.474639415740967\n",
      "37001 0.019753552973270416 2.476149797439575\n",
      "38001 0.01967126503586769 2.476454734802246\n",
      "39001 0.01959412917494774 2.4767260551452637\n",
      "40001 0.019519135355949402 2.47981595993042\n",
      "41001 0.01944638043642044 2.4833321571350098\n",
      "42001 0.019378770142793655 2.484992265701294\n",
      "43001 0.019314704462885857 2.4841158390045166\n",
      "44001 0.019252952188253403 2.4839181900024414\n",
      "45001 0.019195687025785446 2.48574161529541\n",
      "46001 0.019143395125865936 2.48915433883667\n",
      "47001 0.019095798954367638 2.493769884109497\n",
      "48001 0.0190470851957798 2.500458240509033\n",
      "49001 0.018998391926288605 2.5110585689544678\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50000):\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        outputs = net(X_valid)\n",
    "        loss_valid = criterion(outputs, y_valid)\n",
    "        print(epoch + 1, loss.item(), loss_valid.item())\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.193620695879584 25.47861276488555\n",
      "25.725605010986328 25.96190918982029\n",
      "26.790624619314546 26.4775351740812\n",
      "26.549350738211682 25.8547396656714\n",
      "26.679452894863328 26.21907484405919\n",
      "26.143993345059847 24.86085501030872\n",
      "24.624321022786592 23.394879439630007\n",
      "23.667221065571432 22.605400364806776\n",
      "23.38800243327492 23.37576905677193\n",
      "23.729892743261235 20.877672565610784\n",
      "24.111202208619368 21.432042686562788\n",
      "24.508861539865794 23.22151946833259\n",
      "25.268852248003608 25.983844085743552\n",
      "26.084409713745117 27.135578334331512\n",
      "27.0227508403753 28.02400453467118\n",
      "27.623594253941587 26.013001128717473\n",
      "27.091974376377305 26.54725813740178\n",
      "26.963388410367465 25.434598413266635\n",
      "26.370748439588045 22.973363408603166\n",
      "24.83215152840865 23.55512177567733\n",
      "25.315359153245623 23.735083856080706\n",
      "25.57662965122022 23.265480590494054\n",
      "26.050239650826704 23.246814457993757\n",
      "26.717212734724345 23.358791334534946\n",
      "27.22409240823043 24.662781729509955\n",
      "27.63623046875 25.693006098270416\n",
      "28.250402406642312 26.27893377918946\n",
      "26.395015716239026 26.03056609599214\n",
      "25.185480116543015 24.9083655762045\n",
      "24.233331677474474 23.806201030470824\n",
      "22.58970070795009 23.993303933896517\n",
      "22.11909675221694 23.351457532456045\n",
      "22.7046413500058 21.976075388883288\n",
      "22.521661756070035 22.52335470679559\n",
      "22.733989714007627 22.073555616956007\n",
      "23.454322813059154 22.112815437818828\n",
      "25.72358129840148 24.228379770329123\n",
      "27.548276901245117 27.095095098018646\n",
      "28.18790812868821 27.170774892756814\n",
      "27.44452664224725 26.66157540647607\n",
      "25.330526350673875 24.183729826149186\n",
      "23.95768737510631 24.75245359257648\n",
      "22.924203874327635 22.743114540137743\n",
      "22.215806957295065 20.673309799244528\n",
      "21.495750405286486 20.480307974313433\n",
      "22.25970841708936 21.154960048826116\n",
      "22.08606150589491 22.604934392791044\n",
      "22.321928082014384 20.931874094511333\n",
      "23.574132963230735 24.642263515999442\n",
      "25.499608993530273 25.95949274301529\n",
      "25.890855804870004 26.477183461973542\n",
      "25.591907530709317 25.408131807728818\n",
      "24.898065565761765 26.059052823719224\n",
      "24.169143673934435 24.343964722909426\n",
      "23.410678872622942 22.869512604333853\n",
      "22.73114394765151 21.98631780963195\n",
      "22.797069557403262 22.15692245254391\n",
      "23.5951309329585 21.372720373304265\n",
      "24.45730015478636 22.767317978959333\n",
      "25.257026730085673 22.160333571935954\n",
      "\n",
      "\n",
      "2.0950586795806885\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X_valid)\n",
    "loss = criterion(outputs, y_valid)\n",
    "\n",
    "for i in range(60):\n",
    "    print(y_valid[i].item() + month_mean[i % 12, 5255], outputs[i].item() + month_mean[i % 12, 5255])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "tensor([[-1.6852, -0.6216, -0.8943, -0.2422,  1.7275, -0.2259,  0.9207,\n",
      "         -0.3709,  2.8312,  0.6466, -2.8526,  1.6388, -0.2912, -0.0726,\n",
      "         -2.4687, -0.6574,  0.6060,  2.4428, -3.6113, -1.0191, -2.9080,\n",
      "         -2.9458, -0.1578,  2.8558, -0.6879, -0.1257,  2.2011,  1.1495,\n",
      "         -0.6167, -0.8097, -1.4896, -1.6527,  3.1448, -0.9198,  0.3121,\n",
      "          2.5216,  0.4371, -1.7363, -1.8105, -0.9995, -1.3106,  1.7906,\n",
      "         -2.2076, -2.1475, -2.4993,  3.0760,  1.3507, -0.4803,  0.0003,\n",
      "          1.8403, -0.7795, -0.0285, -1.1292, -0.1674,  2.4695, -0.1369,\n",
      "          1.1456,  3.1679, -0.3965, -1.5465, -1.9542, -1.3117, -0.2730,\n",
      "         -1.0788, -0.2687, -3.5032,  1.7496, -1.3449, -1.2721, -0.6779,\n",
      "          0.4330, -2.5400,  0.8411, -0.9258,  0.8932, -2.1141,  3.5134,\n",
      "         -0.8301,  2.6460,  0.8543, -1.3381,  0.8489, -0.3284, -2.9983,\n",
      "          0.9811,  2.0668, -0.3651,  0.3961,  4.5547, -4.5038,  0.6558,\n",
      "          0.0606,  2.5631,  0.9436, -2.7993,  1.2146,  1.1548,  1.4257,\n",
      "          0.7605,  1.0857],\n",
      "        [-0.0485, -1.1232,  0.2417,  0.3879, -1.5615, -2.2706,  0.3806,\n",
      "         -1.3880,  0.6589,  1.1185, -0.1393,  0.2527, -0.0350, -0.3342,\n",
      "         -0.2525,  0.2266, -0.3908, -1.1285,  0.1170,  0.5952, -0.5100,\n",
      "         -2.1100, -0.2640, -0.3361,  0.2928, -0.2169, -0.0086, -0.1352,\n",
      "          1.3371, -1.1866,  0.2924,  1.8252, -0.6997, -0.7491,  0.8543,\n",
      "          1.7440, -0.1180, -0.7460, -0.3986,  1.0585, -0.9575, -0.3732,\n",
      "         -2.1535,  0.0348, -0.3079,  2.0709,  1.4436,  0.7242,  0.3465,\n",
      "         -0.3648,  1.1969,  0.5562, -1.2103, -0.1171, -0.5962, -0.6649,\n",
      "         -0.2343, -0.7077,  1.9672, -0.5749, -0.4225, -0.3570, -0.8044,\n",
      "          0.4868, -0.0525,  0.8550, -1.6628,  0.1536,  2.1382,  2.6009,\n",
      "         -1.1798,  2.2378, -1.3662,  1.2852,  1.6439,  1.6092,  0.7971,\n",
      "         -1.2138,  1.5259,  0.0475, -0.4693, -0.3583,  0.7992,  0.8976,\n",
      "          1.0077,  0.1247,  2.4960, -0.6173, -0.7085, -0.4813, -1.8908,\n",
      "         -0.1752,  0.2853,  0.1805,  0.9468, -0.8979,  1.6228,  0.0720,\n",
      "         -2.1530,  0.0727],\n",
      "        [-0.0409, -0.7130,  1.1290, -0.4835, -1.1287,  1.2185, -1.6759,\n",
      "         -0.1616,  0.3042,  1.6163, -1.3734,  2.7818, -2.5952, -0.7509,\n",
      "         -2.1936,  0.9866, -0.3411,  0.2792,  2.4773,  2.9872,  3.0590,\n",
      "          0.9173,  0.7807, -3.6887, -1.2128,  2.8716, -2.8282, -2.2485,\n",
      "         -1.2484, -2.0941, -1.1437, -2.8976, -2.2348,  3.6458, -1.1036,\n",
      "         -0.0767,  3.0850,  1.6628,  2.6050, -0.9233,  0.1326, -2.2732,\n",
      "         -2.1864,  1.5249, -0.4455,  2.8929, -1.0642,  2.0873,  3.5561,\n",
      "         -1.2086,  0.9189,  1.0322,  0.1759,  0.9425, -1.5175, -1.3393,\n",
      "          2.8448, -1.0282,  1.6510,  0.7329, -1.9671, -0.5263, -0.5688,\n",
      "          1.3981, -2.0856, -1.4533, -0.7374,  1.7191, -0.1451, -1.9731,\n",
      "         -0.0639, -1.0618, -0.8911, -4.0034,  1.2310,  2.2354, -0.3274,\n",
      "          1.4692, -1.8553, -1.0123, -1.4492, -0.0175,  1.8221,  0.5347,\n",
      "         -0.1170, -0.2086,  2.5732,  1.6911,  0.4683,  2.7193, -0.3746,\n",
      "         -0.4133, -2.4051, -1.1228, -1.0143,  0.2761, -2.0098, -0.5584,\n",
      "         -1.8453,  0.7832],\n",
      "        [-0.0930, -1.3530,  2.5921, -0.7222, -1.4413,  1.6615,  0.0388,\n",
      "          2.6839, -2.7031,  0.0852,  0.9929,  0.0275,  0.5192,  0.4229,\n",
      "          0.2018, -0.1051, -0.5927,  1.3913, -0.4150, -0.9038, -0.6660,\n",
      "          2.1649,  1.9130,  0.8401, -0.6352, -0.2259, -0.1917, -1.6230,\n",
      "         -0.5377,  0.8468, -0.4129,  1.5426,  0.1203, -2.8000, -0.0004,\n",
      "          2.5613,  0.8264,  0.5504,  2.4194, -0.5677,  0.4647,  0.9525,\n",
      "          2.3668,  1.0492, -0.4001, -1.6057, -0.0669, -0.0407,  2.0896,\n",
      "         -1.8975, -1.7901,  1.1987, -0.1117, -0.9098,  1.5437, -0.8007,\n",
      "          0.6348, -0.5443, -1.8703,  1.3320, -2.9688, -0.8062, -0.7736,\n",
      "          1.6106,  1.7114,  1.0753,  2.1622,  1.2476, -2.0544, -2.6638,\n",
      "         -2.0411, -0.0857,  0.8020,  1.0762, -2.2933, -1.8736,  0.0630,\n",
      "         -0.0431,  0.1011, -1.8490,  0.2589,  2.3022, -0.7254, -1.2453,\n",
      "         -1.5208,  1.4984,  2.6364, -1.5516,  2.8943,  2.5581,  2.7769,\n",
      "         -0.1384, -0.6660, -1.5589, -2.0382, -0.4812,  0.3286, -2.3416,\n",
      "         -1.4833, -0.0035],\n",
      "        [ 0.0879,  0.7844, -0.8143,  0.5085, -0.0393,  1.0009, -0.0963,\n",
      "         -0.4762, -0.7488, -0.8093,  1.0625, -0.9959, -0.0226,  0.2549,\n",
      "         -0.3919, -0.6642, -0.5298, -0.4555,  0.2650,  0.0010, -0.0165,\n",
      "          0.9299, -0.3198, -0.1612, -0.9456,  0.3164, -0.1538, -0.2814,\n",
      "          0.7637, -0.6859, -0.3471, -0.5238, -0.9007,  0.4349,  0.0055,\n",
      "          0.5728,  0.3622,  0.7754, -0.8718,  0.3682, -0.1715,  0.2034,\n",
      "          0.9124,  0.4739, -0.6152,  0.1077,  0.1522, -0.5675, -0.6784,\n",
      "         -0.3411,  0.1410, -0.5341, -0.3261,  0.2225,  0.2084,  0.4665,\n",
      "          1.3698, -1.2333, -0.1289,  0.5646,  0.5130,  0.9905, -1.0517,\n",
      "          0.1979, -0.2127, -0.2389,  0.4421,  0.0382, -0.3374,  0.3165,\n",
      "          1.2173, -0.0735,  0.1207, -0.1403,  0.9454, -1.1010, -0.6837,\n",
      "          0.0684, -0.5476,  0.6266, -1.0281, -1.0462,  0.0598, -0.0622,\n",
      "          0.4433, -1.3898, -0.8184, -0.3729, -0.2251,  0.0849, -0.0712,\n",
      "          0.0207, -0.2574,  0.2094,  0.2659,  0.3163,  0.3572, -0.4095,\n",
      "          0.7818,  0.5731],\n",
      "        [-1.0297,  0.4866,  0.3953,  0.9347,  0.0983, -0.5679, -1.2734,\n",
      "         -0.4534, -0.3575,  0.2389, -0.2212,  0.3656, -0.0112, -0.3599,\n",
      "          1.4785, -0.0224,  1.0545,  0.1031,  0.0033,  0.4643,  0.5952,\n",
      "         -0.4145, -0.0298,  0.0765, -1.0077,  0.7013,  0.0144, -1.0502,\n",
      "          0.1848,  0.4284, -0.4965,  0.2922,  0.2246, -0.0287,  0.7620,\n",
      "         -0.7154,  0.4417, -0.2116, -0.6674,  0.0492, -0.4200,  0.6024,\n",
      "         -0.5381,  0.2140, -0.3088, -0.6067,  1.2765, -0.3959, -0.5555,\n",
      "          0.5140,  0.4465, -0.2341,  0.9406,  0.6898, -0.6645, -0.6079,\n",
      "          0.1303,  0.3697,  0.3702,  0.2911,  0.0312, -0.1814,  0.2615,\n",
      "         -0.3996, -0.6094,  0.1953,  0.3920, -0.2595,  0.3605, -0.3337,\n",
      "         -1.1028, -0.5248, -0.0618,  0.4922, -0.8587, -0.6961,  0.1995,\n",
      "         -0.2319, -0.2982,  1.4751,  0.4623,  0.8168, -0.4753, -0.3605,\n",
      "         -1.2661,  0.6844, -0.4600, -0.2939, -0.4344,  0.0449,  0.2320,\n",
      "         -0.0374,  0.7473, -0.9098, -0.3107, -0.2727,  0.1705,  0.2062,\n",
      "         -1.1136, -0.7517],\n",
      "        [ 2.4629, -0.4131,  1.9975,  1.1465,  0.1383,  0.3279,  0.0550,\n",
      "         -1.2095, -1.4599, -0.2317,  0.6241, -0.9951,  1.6110, -1.0198,\n",
      "          2.8854, -0.3003,  1.2922,  0.4500,  2.7057, -0.7141,  0.9261,\n",
      "         -0.0459,  0.1848,  0.3499,  1.2954, -0.6171,  0.9936,  0.2969,\n",
      "          0.1747, -2.3619, -0.5182, -0.2702, -2.1343, -1.8727,  0.2709,\n",
      "          1.7877,  0.2619, -0.6836,  0.7835,  0.4389, -1.2374,  0.4340,\n",
      "          1.0566, -0.4018, -0.2038, -1.0061,  1.3028, -0.5928,  0.5290,\n",
      "         -2.2125,  3.7352,  0.1960, -0.4048, -0.2394, -0.1889, -1.3357,\n",
      "         -1.6139, -0.8791,  0.5452,  1.8017,  1.1486, -0.1095, -2.9753,\n",
      "         -0.7646, -0.5855,  1.4102, -0.5305, -1.1170,  1.8906, -0.4913,\n",
      "          0.9614,  0.2827, -0.1180, -0.6193,  0.5332, -0.4937,  0.3798,\n",
      "         -0.1245,  0.3685,  0.1137,  0.0265,  1.3071, -0.5535,  1.1004,\n",
      "         -0.5771, -2.9803,  1.5973,  1.3995, -0.9897,  1.5752,  0.4781,\n",
      "         -0.8502, -1.2542, -1.9345,  1.0811, -1.9823, -0.2406,  0.3924,\n",
      "         -0.3783,  0.4794],\n",
      "        [-0.0403,  0.0539, -0.4709, -0.0936, -0.3132,  0.4235, -0.0683,\n",
      "          1.3486, -0.2357,  0.3794,  0.3249, -1.2494,  0.1773, -0.5997,\n",
      "          0.8156, -0.4903,  0.6893,  0.5696, -0.3696, -0.6310, -0.5531,\n",
      "          0.6753, -0.2827,  0.9217, -0.0156, -0.8490,  0.5379, -0.2823,\n",
      "         -0.9521,  0.2039,  0.7025, -1.0987,  0.0905,  0.3552,  0.5614,\n",
      "         -1.7316, -0.6937,  0.0064,  0.4428, -0.5559,  0.1421, -1.3032,\n",
      "          0.1554, -0.0169,  0.6545, -1.4623,  0.3756, -1.0109,  0.2899,\n",
      "          1.1402,  1.1334,  0.5430,  0.7488,  0.2893,  1.1949, -0.1627,\n",
      "          0.1854,  0.7013, -1.7397, -0.7358,  0.7682, -0.8028, -0.3216,\n",
      "         -0.4730,  0.2798, -0.2920,  1.6143,  0.9102,  1.1076, -0.3953,\n",
      "         -0.1876, -0.5593,  0.0522, -0.2559, -0.0584, -0.4958, -0.2898,\n",
      "          0.8730, -0.6655,  0.2715,  0.1218,  0.1217, -0.9418,  0.2821,\n",
      "         -0.7576,  0.0807, -1.4037,  0.0585,  1.3581, -0.4213,  0.1705,\n",
      "          0.9747, -0.7250, -0.0766, -0.3580,  0.3053, -0.8034,  0.9963,\n",
      "          0.8260, -0.7489]])\n",
      "rnn.weight_hh_l0\n",
      "tensor([[-0.2804,  2.0626],\n",
      "        [-0.7408, -3.5869],\n",
      "        [-0.4787,  3.1896],\n",
      "        [-3.6772,  1.3078],\n",
      "        [ 1.7898,  1.0604],\n",
      "        [-0.2327,  1.7237],\n",
      "        [-2.2687, -4.4906],\n",
      "        [-4.2411, -3.9855]])\n",
      "rnn.bias_ih_l0\n",
      "tensor([ 2.3873, -0.8259,  2.2156,  2.2870, -0.6453,  0.0887,  2.4369,\n",
      "         2.0230])\n",
      "rnn.bias_hh_l0\n",
      "tensor([ 3.7571, -1.2547,  2.7426,  1.8516,  0.1072, -0.4548,  1.7646,\n",
      "         1.1617])\n",
      "fc.weight\n",
      "tensor([[-1.7453, -2.4903]])\n",
      "fc.bias\n",
      "tensor([-0.1931])\n"
     ]
    }
   ],
   "source": [
    "params = net.state_dict()\n",
    "for key, value in params.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测（92°W，0°）今年3月份海温（真实值为27.26599℃）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.156715393066406"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = net(X_test) + month_mean[2, 5255]\n",
    "y_test.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class gru(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(gru, self).__init__()\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=100,\n",
    "            hidden_size=2,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x, None)\n",
    "        x = self.fc(x[:, -1, :])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gru()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = AdaBound(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1.0471551418304443 1.7867462635040283\n",
      "1001 0.5708805322647095 1.4725346565246582\n",
      "2001 0.338470458984375 1.6608353853225708\n",
      "3001 0.23948559165000916 1.7719521522521973\n",
      "4001 0.18859748542308807 2.112320899963379\n",
      "5001 0.16699345409870148 2.272190809249878\n",
      "6001 0.14843274652957916 2.4154255390167236\n",
      "7001 0.13495205342769623 2.3713748455047607\n",
      "8001 0.12770815193653107 2.4031126499176025\n",
      "9001 0.12243083119392395 2.4529356956481934\n",
      "10001 0.11725673079490662 2.461758852005005\n",
      "11001 0.10965229570865631 2.357987880706787\n",
      "12001 0.10369528084993362 2.158215284347534\n",
      "13001 0.09754501283168793 2.1412532329559326\n",
      "14001 0.09261450171470642 1.989659070968628\n",
      "15001 0.09003999084234238 1.8380005359649658\n",
      "16001 0.08835628628730774 1.7944215536117554\n",
      "17001 0.08666938543319702 1.8536418676376343\n",
      "18001 0.08406150341033936 1.9813849925994873\n",
      "19001 0.08242233842611313 1.9778618812561035\n",
      "20001 0.08084326982498169 1.9469146728515625\n",
      "21001 0.07954158633947372 1.99197256565094\n",
      "22001 0.0785195454955101 2.034097671508789\n",
      "23001 0.07757089287042618 2.069472551345825\n",
      "24001 0.07658454030752182 2.09562349319458\n",
      "25001 0.0754891186952591 2.1072473526000977\n",
      "26001 0.07453249394893646 2.126210927963257\n",
      "27001 0.0736924558877945 2.159072160720825\n",
      "28001 0.07285203784704208 2.19317889213562\n",
      "29001 0.07196245342493057 2.205583095550537\n",
      "30001 0.0709758773446083 2.2048115730285645\n",
      "31001 0.07005660980939865 2.227161407470703\n",
      "32001 0.06945417821407318 2.2928826808929443\n",
      "33001 0.0689404159784317 2.374232769012451\n",
      "34001 0.06848529726266861 2.4344143867492676\n",
      "35001 0.06801269203424454 2.472438335418701\n",
      "36001 0.06753308326005936 2.508984327316284\n",
      "37001 0.06703127175569534 2.5572659969329834\n",
      "38001 0.06660500168800354 2.5627055168151855\n",
      "39001 0.06621944904327393 2.5502610206604004\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(40000):\n",
    "    outputs = net(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 1000 == 0:\n",
    "        outputs = net(X_valid)\n",
    "        loss_valid = criterion(outputs, y_valid)\n",
    "        print(epoch + 1, loss.item(), loss_valid.item())\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.193620695879584 26.962858601620322\n",
      "25.725605010986328 27.34829831123352\n",
      "26.790624619314546 27.675266698787087\n",
      "26.549350738211682 26.471346705838254\n",
      "26.679452894863328 25.41476666801854\n",
      "26.143993345059847 24.371585574902987\n",
      "24.624321022786592 23.83999363497684\n",
      "23.667221065571432 22.94352531056655\n",
      "23.38800243327492 22.765628375505145\n",
      "23.729892743261235 23.182628524930852\n",
      "24.111202208619368 23.508448092561018\n",
      "24.508861539865794 24.12108903935081\n",
      "25.268852248003608 25.26747266869796\n",
      "26.084409713745117 25.91914939880371\n",
      "27.0227508403753 27.020505742022866\n",
      "27.623594253941587 26.31566992370706\n",
      "27.091974376377305 25.248362778362473\n",
      "26.963388410367465 24.13625940398166\n",
      "26.370748439588045 23.243037560739015\n",
      "24.83215152840865 22.802320118954306\n",
      "25.315359153245623 22.764975823854144\n",
      "25.57662965122022 23.054406893880742\n",
      "26.050239650826704 25.194422571282637\n",
      "26.717212734724345 25.718181429411235\n",
      "27.22409240823043 24.80542854886306\n",
      "27.63623046875 26.273600816726685\n",
      "28.250402406642312 26.553573206851357\n",
      "26.395015716239026 26.558289855404905\n",
      "25.185480116543015 23.70514821880742\n",
      "24.233331677474474 22.009737816609835\n",
      "22.58970070795009 23.090097466268038\n",
      "22.11909675221694 20.51936030011428\n",
      "22.7046413500058 22.764781870340045\n",
      "22.521661756070035 23.05441011253156\n",
      "22.733989714007627 23.369171349625837\n",
      "23.454322813059154 21.722318587805095\n",
      "25.72358129840148 22.971151395847922\n",
      "27.548276901245117 24.652827858924866\n",
      "28.18790812868821 25.16645069498765\n",
      "27.44452664224725 24.92136260835748\n",
      "25.330526350673875 23.834138034519395\n",
      "23.95768737510631 22.77252217844913\n",
      "22.924203874327635 21.913387695111727\n",
      "22.215806957295065 22.071701165249472\n",
      "21.495750405286486 22.405709840749438\n",
      "22.25970841708936 22.61889768901624\n",
      "22.08606150589491 23.026929347138655\n",
      "22.321928082014384 23.25255077889091\n",
      "23.574132963230735 24.547994419148093\n",
      "25.499608993530273 26.179797768592834\n",
      "25.890855804870004 27.391418770739907\n",
      "25.591907530709317 26.346758335515073\n",
      "24.898065565761765 25.217259226974686\n",
      "24.169143673934435 24.1190704377074\n",
      "23.410678872622942 23.21778205946872\n",
      "22.73114394765151 22.41615461926711\n",
      "22.797069557403262 21.91171029994362\n",
      "23.5951309329585 21.941429389150517\n",
      "24.45730015478636 22.342063872437727\n",
      "25.257026730085673 22.925119338537517\n",
      "\n",
      "\n",
      "2.2710580825805664\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X_valid)\n",
    "loss = criterion(outputs, y_valid)\n",
    "\n",
    "for i in range(60):\n",
    "    print(y_valid[i].item() + month_mean[i % 12, 5255], outputs[i].item() + month_mean[i % 12, 5255])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "tensor([[ 0.8344, -0.3500, -0.0581,  0.0982, -0.6910, -1.0347,  0.3074,\n",
      "          0.2870,  0.8660, -0.5590, -0.6626,  0.0441,  0.6067, -0.1940,\n",
      "         -0.4461,  0.1219, -0.7096, -0.1682,  0.3684, -0.6149, -0.8333,\n",
      "          0.4449, -0.2600,  0.9455, -0.4028,  0.0580, -0.4838,  0.4083,\n",
      "         -0.4237,  0.3088, -0.1605, -0.4153,  0.0464,  0.9482, -0.8600,\n",
      "         -0.6242,  0.2687, -0.2363, -0.4043, -0.8294,  0.1945,  0.6232,\n",
      "          0.0324, -0.8341, -0.3535,  0.1316,  0.3326,  0.0675,  0.7847,\n",
      "          0.1195, -0.3454,  0.6425,  0.4323,  0.3332,  0.5363, -0.0327,\n",
      "         -0.6294, -0.0044, -0.7570, -0.6438, -0.7693,  1.0778,  0.4016,\n",
      "         -0.6724,  0.6232,  0.3999,  0.1594, -0.2706,  0.0476, -0.2164,\n",
      "          0.8526, -0.7801,  0.9971, -1.1252, -0.8131, -0.6199, -0.0972,\n",
      "         -0.6818, -0.6804,  0.6346, -0.4428, -0.3139,  0.5396, -0.6833,\n",
      "         -0.1957, -0.5859, -0.5580, -1.1487,  0.5200,  0.3138, -0.3225,\n",
      "         -0.7316,  0.0303,  0.9403,  0.3220, -0.2522, -0.0410, -0.6345,\n",
      "         -0.6032, -0.1369],\n",
      "        [-0.1016, -0.6449, -0.5512, -0.0538, -0.0660,  0.4814, -0.3947,\n",
      "          0.8673, -0.6252, -0.1249,  0.2900,  0.6059,  0.8893,  0.1348,\n",
      "          0.2684,  0.2252, -0.4258, -0.8717, -0.9018,  0.0010,  0.3322,\n",
      "          0.0731, -0.3251,  0.5588,  0.0560,  0.6133,  0.5662,  0.5096,\n",
      "          0.2686, -0.5670,  0.9604,  0.8282,  0.3346, -0.4889,  0.9699,\n",
      "         -0.6607,  0.7263, -0.5436, -0.9395, -0.0512, -0.2576,  0.3990,\n",
      "          0.1768,  0.1634, -0.1436,  0.3438,  0.5152, -0.0711, -0.2227,\n",
      "         -0.4595,  0.5280,  0.1338,  0.3177,  0.8771,  0.7769,  0.8981,\n",
      "         -0.1114, -0.6881, -0.9955, -0.1954,  0.4024, -0.3198, -0.4880,\n",
      "          0.1871, -0.0897, -0.7800,  0.2673, -0.6955, -0.2051,  0.0447,\n",
      "          0.4232, -0.2756,  0.7022, -0.7384, -0.2522, -0.8327,  0.2860,\n",
      "         -0.8970,  0.7515,  0.2766, -0.3504, -0.1045,  0.4146,  0.7869,\n",
      "          0.7210,  0.0379, -0.3624,  0.9093,  0.2683,  0.4914, -0.1870,\n",
      "          0.5354, -0.0899, -0.2837, -0.1556, -1.1192,  0.3908, -0.3184,\n",
      "          0.6026, -0.1402],\n",
      "        [-1.1271,  1.0411, -1.2746,  0.5331,  0.9576,  0.7886,  0.3841,\n",
      "         -0.5611, -0.3842, -0.0278, -0.3059, -1.9992, -0.1986, -0.1656,\n",
      "         -0.8559, -0.6386,  0.3721,  1.1081,  0.8228,  0.5222,  0.7881,\n",
      "          0.0845,  0.0388,  0.9586,  1.5965, -1.0049,  0.4452,  0.2068,\n",
      "         -0.5654, -0.5528,  0.2304, -0.0937, -0.5702, -0.5051, -1.3025,\n",
      "          0.5574,  1.3424, -1.3924, -0.3782, -0.1406,  0.5471,  0.5395,\n",
      "          0.2199,  1.8898,  2.1852, -0.2484,  1.0274,  0.4902,  1.3223,\n",
      "         -0.1798, -0.5156, -0.8628, -0.5654, -1.4359, -1.1109,  0.9794,\n",
      "          1.7160, -0.8515,  0.4797, -0.4235, -0.2830,  0.8779,  0.0650,\n",
      "         -0.6089,  0.5111, -0.6518,  0.4466,  0.7947, -1.1129, -0.0099,\n",
      "         -0.0679, -0.3225, -0.9124,  0.3838,  0.6174, -0.2836, -0.0425,\n",
      "          0.2329, -0.1908, -0.4999,  1.0864, -1.4510, -0.2722,  0.7741,\n",
      "         -0.6027, -1.0025, -0.1344, -0.7696, -1.7728,  2.1428,  1.2110,\n",
      "         -0.6393, -0.2030,  0.3487,  0.9890,  0.4530,  0.1453,  0.3361,\n",
      "          0.7661,  0.4814],\n",
      "        [-0.1796, -1.0497, -0.2329,  0.3773,  0.3742,  1.4899,  0.0128,\n",
      "         -0.2990, -0.9553,  0.0321, -0.7610, -0.3302,  0.0750,  0.0978,\n",
      "         -0.0720, -1.3742,  0.3672, -0.2898,  0.0956,  0.0922,  0.0859,\n",
      "         -0.3379, -0.5415, -0.0515, -0.4865, -1.8266,  1.4446,  0.0521,\n",
      "          0.6932, -0.2167,  0.3747,  0.6102, -0.3299, -0.0469,  0.2582,\n",
      "         -0.4997, -1.3058, -0.6281,  0.1962, -0.5108, -0.2165, -0.4374,\n",
      "          0.3016, -0.3001,  0.9758, -0.6358,  0.5741, -0.5852, -1.0078,\n",
      "          0.1670, -0.3639, -0.2760, -1.0678,  0.4782,  0.7811, -0.0831,\n",
      "          0.6070,  0.3536,  0.0606,  1.3982, -0.0203, -0.3219,  0.5429,\n",
      "         -0.0562, -0.4508,  0.6801,  0.2039, -0.1517, -0.4863, -0.4165,\n",
      "         -0.1874,  0.3388,  0.4251, -0.6985, -0.0855,  0.9344, -0.7772,\n",
      "         -0.1677,  0.1662, -0.7046, -0.0267,  1.1173, -0.8303, -0.6469,\n",
      "         -0.5407,  0.6634,  0.3702,  0.1075, -0.7662,  0.4677,  0.0559,\n",
      "         -0.3475,  1.7720, -1.1233,  0.4023,  0.1283, -0.3465, -1.2569,\n",
      "         -0.0913, -0.2178],\n",
      "        [-0.8386,  0.4182,  0.2491,  1.7616,  0.0721,  0.8003, -0.3167,\n",
      "         -0.8923, -0.8222, -0.5196, -0.2877,  0.2372,  0.5780,  0.4324,\n",
      "          1.3277, -0.1351, -0.1244, -0.1984, -0.5665,  0.2576,  0.3750,\n",
      "         -0.4697, -1.2397,  0.1964, -1.1326, -0.3955, -0.7920, -0.0667,\n",
      "          0.0762,  0.1721, -0.1013, -0.3129, -0.1965,  0.1530,  0.5272,\n",
      "          0.1952, -0.3477,  0.0271, -0.0197,  0.0999, -0.4213,  0.3650,\n",
      "         -0.6101, -0.5219, -0.9142,  0.2472,  0.2757, -0.0811, -0.4990,\n",
      "          0.6108, -0.6678,  0.6664, -0.1656,  0.7691,  0.5175,  0.0953,\n",
      "         -0.2979,  0.7881, -0.4132,  0.1796, -0.0611, -1.1198,  0.1136,\n",
      "          0.0544, -0.2655,  0.6540,  0.6249,  0.0950, -0.1537, -0.7375,\n",
      "          0.2500,  0.5554,  0.7596, -0.0118, -0.5481,  0.2751, -0.7524,\n",
      "          0.2531, -0.0627, -0.0748, -0.4182, -0.0587,  0.7839, -1.0819,\n",
      "          0.1340, -0.0138, -0.9632,  0.0962,  0.4950, -0.5057, -0.0123,\n",
      "         -0.7481,  0.2524, -0.5593,  0.3885, -0.2024, -0.1735, -0.4585,\n",
      "         -0.3870,  0.1437],\n",
      "        [ 0.8889, -1.9971,  0.0280, -0.9491,  0.3048,  0.5266,  1.6222,\n",
      "          0.0368, -0.2395, -0.2417, -0.9375, -0.0086,  0.6030, -0.3644,\n",
      "         -0.4600, -0.5072, -0.4164,  0.4610,  0.3272, -0.1388,  1.0118,\n",
      "         -1.2951, -0.8005, -0.6654, -0.3214, -0.5415,  0.3161,  0.0075,\n",
      "         -0.3288,  0.0917,  0.2200,  0.1738, -0.5494, -0.5597,  0.2288,\n",
      "          0.0562, -0.5221, -0.3879,  0.3748,  0.1461, -0.3881, -0.8920,\n",
      "          0.0129,  0.5140,  0.0241,  0.3310,  0.1727, -0.2090,  0.0315,\n",
      "          0.5187,  0.1853, -0.4503, -0.4440,  0.1127,  0.1789,  0.8064,\n",
      "          0.0692,  0.8768,  0.0724,  0.2542,  0.4095, -1.0846, -0.2210,\n",
      "          0.4215,  0.1220,  0.4167, -0.1401, -0.1627, -0.2888, -0.3275,\n",
      "          0.1551,  0.0336,  0.9489, -0.4278,  0.1641,  0.0870, -0.3144,\n",
      "         -0.1379,  0.2840, -0.6482, -0.0271,  0.4535,  0.4525, -0.0041,\n",
      "         -0.2386,  0.8166, -0.1203,  0.1907, -0.0361, -0.3180,  0.3861,\n",
      "         -0.8304,  0.5576, -0.3399,  0.0186,  0.2769, -0.0317, -0.1475,\n",
      "         -0.1433, -0.2249]])\n",
      "rnn.weight_hh_l0\n",
      "tensor([[ 1.2142, -0.8163],\n",
      "        [ 0.8030,  0.3871],\n",
      "        [-0.3299, -1.3859],\n",
      "        [-0.3224, -0.3925],\n",
      "        [-2.4048,  3.0377],\n",
      "        [-0.8477,  0.2401]])\n",
      "rnn.bias_ih_l0\n",
      "tensor([ 0.2273,  0.0458,  1.0242,  0.2236,  1.4029,  0.0533])\n",
      "rnn.bias_hh_l0\n",
      "tensor([ 0.3230,  0.1189,  1.5345,  0.1204, -2.7346, -2.9236])\n",
      "fc.weight\n",
      "tensor([[-1.1465,  1.4892]])\n",
      "fc.bias\n",
      "tensor([ 0.7518])\n"
     ]
    }
   ],
   "source": [
    "params = net.state_dict()\n",
    "for key, value in params.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
